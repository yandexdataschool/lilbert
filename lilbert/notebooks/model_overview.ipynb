{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib import size_utils, tasks, data_processors, feature_processors, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "params = {\n",
    "    'data_dir': '../../data/SST-2',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'eval_batch_size': 20,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "# We take only one batch of evaluation examples.\n",
    "eval_examples = processor.get_dev_examples(\n",
    "    params['data_dir'])[:params['eval_batch_size']]\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the number of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 23837184,\n",
       " 'encoder': 85054464,\n",
       " 'pooler': 590592,\n",
       " 'total': 109483778}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = {\n",
    "    'embedding': 0,\n",
    "    'encoder': 0,\n",
    "    'pooler': 0,\n",
    "    'total': 0\n",
    "}\n",
    "\n",
    "weights = model.state_dict()\n",
    "for layer_name, layer in weights.items():\n",
    "    layer_params_num = len(layer.cpu().numpy().ravel())\n",
    "    for name in num_params:\n",
    "        if name in layer_name:\n",
    "            num_params[name] += layer_params_num\n",
    "    num_params['total'] += layer_params_num\n",
    "    \n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 0.21772343296374008,\n",
       " 'encoder': 0.7768681858969098,\n",
       " 'pooler': 0.005394333396131069}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params_shares = {\n",
    "    layer: num_params[layer] * 1.0 / num_params['total']\n",
    "    for layer in num_params\n",
    "    if layer != 'total'\n",
    "}\n",
    "\n",
    "num_params_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'417.69311809539795 MB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_utils.get_model_size(model, params['cache_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying to a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_features = feature_processors.convert_examples_to_features(\n",
    "    eval_examples,\n",
    "    params['label_list'],\n",
    "    params['max_seq_length'],\n",
    "    tokenizer)\n",
    "input_ids = torch.tensor(\n",
    "    [f.input_ids for f in eval_features],\n",
    "     dtype=torch.long).to(params['device'])\n",
    "input_mask = torch.tensor(\n",
    "    [f.input_mask for f in eval_features],\n",
    "     dtype=torch.long).to(params['device'])\n",
    "segment_ids = torch.tensor(\n",
    "    [f.segment_ids for f in eval_features],\n",
    "     dtype=torch.long).to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5950677 , 0.4049324 ],\n",
       "       [0.633476  , 0.36652398],\n",
       "       [0.62468827, 0.3753117 ],\n",
       "       [0.5904694 , 0.40953058],\n",
       "       [0.6217312 , 0.37826872],\n",
       "       [0.5833395 , 0.4166605 ],\n",
       "       [0.61120874, 0.38879126],\n",
       "       [0.57841194, 0.42158806],\n",
       "       [0.61265224, 0.38734776],\n",
       "       [0.6302714 , 0.36972862],\n",
       "       [0.5941279 , 0.40587205],\n",
       "       [0.599353  , 0.40064695],\n",
       "       [0.59727263, 0.40272734],\n",
       "       [0.59377027, 0.4062298 ],\n",
       "       [0.60265714, 0.3973429 ],\n",
       "       [0.5771439 , 0.42285612],\n",
       "       [0.56967974, 0.43032026],\n",
       "       [0.5727943 , 0.42720568],\n",
       "       [0.602853  , 0.39714694],\n",
       "       [0.6229316 , 0.3770684 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "logits = model(input_ids, segment_ids, input_mask).detach().cpu()\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "y_pred = softmax(logits).numpy()\n",
    "y_true = np.array([int(example.label) \n",
    "                   for i, example in enumerate(eval_examples)])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая точность у незафайнтьюненной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
