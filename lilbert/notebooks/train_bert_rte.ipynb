{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f86622ae310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "params = {\n",
    "    'data_dir': '../datasets/RTE',\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'rte',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:36<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.7008157930313013, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6681361278041605, 'eval_accuracy': 0.5992779783393501, 'eval_f1_score': 0.5873605947955391, 'eval_matthews_corrcoef': 0.20621234891822715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.6767277950659777, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6643979622568895, 'eval_accuracy': 0.592057761732852, 'eval_f1_score': 0.6626865671641792, 'eval_matthews_corrcoef': 0.17678265696515783}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:35<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.5593152191394415, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.647120522973985, 'eval_accuracy': 0.6498194945848376, 'eval_f1_score': 0.6881028938906752, 'eval_matthews_corrcoef': 0.29515603368584087}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:35<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.3729557619454005, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7789937539315288, 'eval_accuracy': 0.6173285198555957, 'eval_f1_score': 0.6845238095238094, 'eval_matthews_corrcoef': 0.23143089615411272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:37<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.2733649337091125, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9758022572737631, 'eval_accuracy': 0.6642599277978339, 'eval_f1_score': 0.7084639498432601, 'eval_matthews_corrcoef': 0.32576228102748156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:37<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.2784867717239719, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1060749355258945, 'eval_accuracy': 0.6462093862815884, 'eval_f1_score': 0.7012195121951219, 'eval_matthews_corrcoef': 0.29051665718428304}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 2490\n",
      "Batch size:   32\n",
      "Num steps:    77\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 78/78 [00:36<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.23839517706670824, 'train_global_step': 78}\n",
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4871535574429373, 'eval_accuracy': 0.6389891696750902, 'eval_f1_score': 0.7175141242937854, 'eval_matthews_corrcoef': 0.2903802456679771}\n"
     ]
    }
   ],
   "source": [
    "TOTAL_EPOCH_NUMS = 7\n",
    "\n",
    "for epoch_num in range(1, TOTAL_EPOCH_NUMS + 1):\n",
    "    params['num_train_epochs'] = 1\n",
    "    checkpoint_files = {\n",
    "        'config': 'bert_config.json',\n",
    "        'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "            params['task_name'], epoch_num)\n",
    "    }\n",
    "\n",
    "    model, result = train(model, tokenizer, params,\n",
    "                          train_examples,\n",
    "                          valid_examples=dev_examples,\n",
    "                          checkpoint_files=checkpoint_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 5\n",
    "\n",
    "best_model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "\n",
    "best_model.load_state_dict(torch.load(\n",
    "    os.path.join(params['output_dir'], 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], best_epoch))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  277\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 35/35 [00:01<00:00, 26.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9758022572737631,\n",
       " 'eval_accuracy': 0.6642599277978339,\n",
       " 'eval_f1_score': 0.7084639498432601,\n",
       " 'eval_matthews_corrcoef': 0.32576228102748156}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(best_model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
