{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuantArchitecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VUNTByihjeLK",
        "colab_type": "code",
        "outputId": "a1502541-b55e-48b5-825d-7ecd75e3062d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KlT-qAkyjniK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O \"SST-2.zip\" 'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8'\n",
        "!unzip \"SST-2.zip\"\n",
        "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
        "    \n",
        "!pip install -r lilbert/requirements.txt\n",
        "!mkdir ./lilbert/output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cAPMM5hMjueY",
        "colab_type": "code",
        "outputId": "d66717f9-8281-40e8-f33a-579e2fef1670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "sys.path.append('lilbert/lilbert')\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "\n",
        "from lib import data_processors, tasks\n",
        "from lib.bert import BertForSequenceClassification\n",
        "from lib.train_eval import train, evaluate, predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aZ7IGxMHjwWo",
        "colab_type": "code",
        "outputId": "d593441d-768b-42b3-b5cf-ea0e71046817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%env CUDA_VISIBLE_DEVICES=1\n",
        "\n",
        "params = {\n",
        "    'data_dir': 'SST-2',\n",
        "    'output_dir': '../output',\n",
        "    'cache_dir': '../model_cache',\n",
        "    'task_name': 'sst2',\n",
        "    'bert_model': 'bert-base-uncased',\n",
        "    'max_seq_length': 128,\n",
        "    'train_batch_size': 32,\n",
        "    'eval_batch_size': 8,\n",
        "    'learning_rate': 2e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'num_train_epochs': 1,\n",
        "    'seed': 1331,\n",
        "    'device': torch.device(\n",
        "        'cuda' if torch.cuda.is_available()\n",
        "        else 'cpu')\n",
        "}\n",
        "\n",
        "random.seed(params['seed'])\n",
        "np.random.seed(params['seed'])\n",
        "torch.manual_seed(params['seed'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdc0307b130>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "VhnMoc8Gjx9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = params['device']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CB6Rgf3Vj3-0",
        "colab_type": "code",
        "outputId": "1f5d2092-c1bb-4f47-fda7-1a63fc68f4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
        "params['label_list'] = tasks.label_lists[params['task_name']]\n",
        "\n",
        "processor = tasks.processors[params['task_name']]()\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    params['bert_model'], do_lower_case=True)\n",
        "\n",
        "train_examples = processor.get_train_examples(params['data_dir'])\n",
        "dev_examples = processor.get_dev_examples(params['data_dir'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2597699.64B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VBCX2HH_j5_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSXAsmqxTCC4",
        "colab_type": "code",
        "outputId": "749071a5-57db-4e13-fafe-7808e361f2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    params['bert_model'],\n",
        "    cache_dir=params['cache_dir'],\n",
        "    num_labels=params['num_labels']).to(params['device'])\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:12<00:00, 32256152.88B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fZccGlECVS1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.bert.encoder.state_dict(), \"model-all-enc.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vP_CADqOfZsG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import math\n",
        "class QuantizedLayer(torch.nn.Module):\n",
        "    def __init__(self, layer=None, n_clusters=8,  size=None):\n",
        "        super(QuantizedLayer, self).__init__()\n",
        "        self.n_bits = math.ceil(math.log2(n_clusters)) # int64\n",
        "        self.code_size = 63 // self.n_bits  # 8 clusters to 63 bits\n",
        "        self.emb_layer = emb_layer\n",
        "        \n",
        "        if layer is None:\n",
        "            if size is None:\n",
        "                raise ValueError(\"During random init, size must be passed.\")\n",
        "            self.matrix_size = size\n",
        "            \n",
        "            centroids = torch.randn(n_clusters).view(-1,1)\n",
        "            centroids_idx = torch.randint(low=0, high=n_clusters, size=size).view(-1)\n",
        "            self.bias=torch.nn.Parameter(torch.randn(size[0]))\n",
        "        else:\n",
        "            self.matrix_size = layer.weight.size()\n",
        "            algo = MiniBatchKMeans(n_clusters)\n",
        "            points = layer.weight.view(-1, 1).detach().cpu().numpy()\n",
        "            algo.fit(points)\n",
        "            \n",
        "            centroids = torch.Tensor(algo.cluster_centers_)\n",
        "            centroids_idx = torch.LongTensor(algo.predict(points))\n",
        "            if hasattr(layer, 'bias'):\n",
        "                self.bias = torch.nn.Parameter(layer.bias)\n",
        "            else:\n",
        "                self.bias = None\n",
        "            \n",
        "        pad = torch.zeros(-len(centroids_idx) % self.code_size).long()\n",
        "        to_code = torch.cat([centroids_idx, pad]).view(-1, self.code_size)\n",
        "        \n",
        "        self.codes = torch.nn.Parameter(\n",
        "            torch.sum(to_code.long() * torch.LongTensor([(2 ** self.n_bits) ** i for i in range(self.code_size)]), dim=-1),\n",
        "                                        requires_grad=False) \n",
        "        self.codes_emb = torch.nn.Embedding.from_pretrained(centroids)\n",
        "        \n",
        "        \n",
        "    def forward(self, input_):\n",
        "          decoded = self.codes.view(-1, 1) //\\\n",
        "                              torch.LongTensor([(2 ** self.n_bits) ** i for i in range(self.code_size)]).to(input_.device) %\\\n",
        "                              torch.LongTensor([(2 ** self.n_bits) for _ in range(self.code_size)]).to(input_.device)\n",
        "          decoded = decoded.view(-1)[:self.matrix_size.numel()]\n",
        "          weight = self.codes_emb(decoded)\n",
        "          weight = weight.view(self.matrix_size)\n",
        "          return torch.functional.F.linear(input_, weight, self.bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHvET5fGVCdp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Without training:"
      ]
    },
    {
      "metadata": {
        "id": "IQNVx5hH637g",
        "colab_type": "code",
        "outputId": "d6dec958-0bc1-4fda-d5ca-e72d4a271a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = params['device']\n",
        "n_clusters = 4\n",
        "for transformer_layer_ind in tqdm(range(12)):\n",
        "    \n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [10:29<00:00, 51.52s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "irn8KesH8wJ6",
        "colab_type": "code",
        "outputId": "7a7c6aaf-a788-4bfe-a8c5-f6f3f79f3aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "result, prob_preds = evaluate(model, tokenizer, params,\n",
        "                              dev_examples)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.8555045871559633,\n",
              " 'eval_f1_score': 0.8545034642032333,\n",
              " 'eval_loss': 0.3484584675960824,\n",
              " 'eval_matthews_corrcoef': 0.7120853635082497}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "vcbUFnkOVLoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With training:"
      ]
    },
    {
      "metadata": {
        "id": "xEAL2zteCWW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    params['bert_model'],\n",
        "    cache_dir=params['cache_dir'],\n",
        "    num_labels=params['num_labels']).to(params['device'])\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Porr4FRlKkmI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "blocks = [\n",
        "    [6, 3, 7,  8],\n",
        "    [4, 5, 0, 11],\n",
        "    [9, 2, 10, 1]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FN6B9asVKIBq",
        "colab_type": "code",
        "outputId": "d1172153-7197-4a1f-d25c-3eac2d0ed227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "cell_type": "code",
      "source": [
        "device = params['device']\n",
        "n_clusters = 4\n",
        "for i, block in enumerate(blocks):\n",
        "    for transformer_layer_ind in tqdm(block):\n",
        "        model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
        "\n",
        "        model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
        "\n",
        "\n",
        "        model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
        "\n",
        "\n",
        "        model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "        model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "        model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
        "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)\n",
        "\n",
        "    EPOCH_NUM = i\n",
        "\n",
        "    params['num_train_epochs'] = 1\n",
        "    checkpoint_files = {\n",
        "        'config': 'bert_config.json',\n",
        "        'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
        "            params['task_name'], EPOCH_NUM)\n",
        "    }\n",
        "\n",
        "    model, result = train(model, tokenizer, params,\n",
        "                          train_examples,\n",
        "                          valid_examples=dev_examples,\n",
        "                          checkpoint_files=checkpoint_files)\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [03:25<00:00, 51.27s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "Num examples: 67349\n",
            "Batch size:   32\n",
            "Num steps:    2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 2105/2105 [49:54<00:00,  1.29s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.1246670034977291, 'train_global_step': 2105}\n",
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:16<00:00,  6.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2155188312978989, 'eval_accuracy': 0.9151376146788991, 'eval_f1_score': 0.9174107142857143, 'eval_matthews_corrcoef': 0.8303008389339931}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.1246670034977291, 'train_global_step': 2105}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [03:25<00:00, 50.94s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "Num examples: 67349\n",
            "Batch size:   32\n",
            "Num steps:    2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 2105/2105 [46:07<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.07454932219837737, 'train_global_step': 2105}\n",
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.24157569218345373, 'eval_accuracy': 0.9197247706422018, 'eval_f1_score': 0.9220489977728284, 'eval_matthews_corrcoef': 0.8395490166354784}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.07454932219837737, 'train_global_step': 2105}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [03:19<00:00, 50.01s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "Num examples: 67349\n",
            "Batch size:   32\n",
            "Num steps:    2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 2105/2105 [42:15<00:00,  1.10s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.07110275359483625, 'train_global_step': 2105}\n",
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.25014348505286876, 'eval_accuracy': 0.9151376146788991, 'eval_f1_score': 0.9185022026431717, 'eval_matthews_corrcoef': 0.8309517687830787}\n",
            "{'train_loss': 0.07110275359483625, 'train_global_step': 2105}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LNwPEkXdwdrB",
        "colab_type": "code",
        "outputId": "b53059a6-888d-4423-cb54-911d46b1b065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "result, prob_preds = evaluate(model, tokenizer, params,\n",
        "                              dev_examples)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.9151376146788991,\n",
              " 'eval_f1_score': 0.9185022026431717,\n",
              " 'eval_loss': 0.25014348505286876,\n",
              " 'eval_matthews_corrcoef': 0.8309517687830787}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "g0CHjAT5wihk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.bert.encoder.state_dict(), 'model-4-tr-enc.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4XtQbQTVqFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "8 clusters:"
      ]
    },
    {
      "metadata": {
        "id": "YnKw67dfVt8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    params['bert_model'],\n",
        "    cache_dir=params['cache_dir'],\n",
        "    num_labels=params['num_labels']).to(params['device'])\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4Ro_AtNB1Ed",
        "colab_type": "code",
        "outputId": "aa2ffce7-27a7-46c6-f913-ae2a6fcbb3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = params['device']\n",
        "n_clusters = 8\n",
        "for transformer_layer_ind in tqdm(range(12)):\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
        "\n",
        "\n",
        "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
        "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [10:31<00:00, 53.45s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KBD2wev2CSgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.bert.encoder.state_dict(), 'model8_enc.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kz3483N4FT6H",
        "colab_type": "code",
        "outputId": "81af6ea5-6844-4b4c-ef72-9ae7e69ece4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 843292\n",
            "-rw-r--r-- 1 root root 437982975 Apr  9 14:21 model.pt\n",
            "-rw-r--r-- 1 root root 340259226 Apr  9 16:55 model-all-enc.pt\n",
            "-rw-r--r-- 1 root root  32895719 Apr  9 17:11 model8_enc.pt\n",
            "-rw-r--r-- 1 root root  22456619 Apr  9 16:54 model4_enc.pt\n",
            "-rw-r--r-- 1 root root  22456619 Apr  9 16:54 model4.pt\n",
            "-rw-r--r-- 1 root root   7439277 May  2  2018 SST-2.zip\n",
            "drwxr-xr-x 6 root root      4096 Apr  9 14:20 lilbert\n",
            "drwxr-xr-x 1 root root      4096 Apr  4 20:20 sample_data\n",
            "drwxrwxr-x 3 root root      4096 May  2  2018 SST-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-hcwAPvWVv51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e4319663-1424-4ab9-b73f-f4af65340b67"
      },
      "cell_type": "code",
      "source": [
        "print(\"Compression rate of encoder, 8 clusters: {}\".format(340259226 / 32895719))\n",
        "print(\"Compression rate of encoder, 4 clusters: {}\".format(340259226 / 22456619))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compression rate of encoder, 8 clusters: 10.343571636175517\n",
            "Compression rate of encoder, 4 clusters: 15.151845698588911\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}