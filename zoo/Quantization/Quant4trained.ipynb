{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VUNTByihjeLK",
    "outputId": "a1502541-b55e-48b5-825d-7ecd75e3062d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlT-qAkyjniK"
   },
   "outputs": [],
   "source": [
    "!wget -O \"SST-2.zip\" 'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8'\n",
    "!unzip \"SST-2.zip\"\n",
    "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
    "    \n",
    "!pip install -r lilbert/requirements.txt\n",
    "!mkdir ./lilbert/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cAPMM5hMjueY",
    "outputId": "d66717f9-8281-40e8-f33a-579e2fef1670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('lilbert/lilbert')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aZ7IGxMHjwWo",
    "outputId": "d593441d-768b-42b3-b5cf-ea0e71046817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc0307b130>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "params = {\n",
    "    'data_dir': 'SST-2',\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhnMoc8Gjx9v"
   },
   "outputs": [],
   "source": [
    "device = params['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CB6Rgf3Vj3-0",
    "outputId": "1f5d2092-c1bb-4f47-fda7-1a63fc68f4bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 2597699.64B/s]\n"
     ]
    }
   ],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBCX2HH_j5_O"
   },
   "outputs": [],
   "source": [
    "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XSXAsmqxTCC4",
    "outputId": "749071a5-57db-4e13-fafe-7808e361f2c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:12<00:00, 32256152.88B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZccGlECVS1S"
   },
   "outputs": [],
   "source": [
    "torch.save(model.bert.encoder.state_dict(), \"model-all-enc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vP_CADqOfZsG"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import math\n",
    "class QuantizedLayer(torch.nn.Module):\n",
    "    def __init__(self, layer=None, n_clusters=8,  size=None):\n",
    "        super(QuantizedLayer, self).__init__()\n",
    "        self.n_bits = math.ceil(math.log2(n_clusters)) # int64\n",
    "        self.code_size = 63 // self.n_bits  # 8 clusters to 63 bits\n",
    "        self.emb_layer = emb_layer\n",
    "        \n",
    "        if layer is None:\n",
    "            if size is None:\n",
    "                raise ValueError(\"During random init, size must be passed.\")\n",
    "            self.matrix_size = size\n",
    "            \n",
    "            centroids = torch.randn(n_clusters).view(-1,1)\n",
    "            centroids_idx = torch.randint(low=0, high=n_clusters, size=size).view(-1)\n",
    "            self.bias=torch.nn.Parameter(torch.randn(size[0]))\n",
    "        else:\n",
    "            self.matrix_size = layer.weight.size()\n",
    "            algo = MiniBatchKMeans(n_clusters)\n",
    "            points = layer.weight.view(-1, 1).detach().cpu().numpy()\n",
    "            algo.fit(points)\n",
    "            \n",
    "            centroids = torch.Tensor(algo.cluster_centers_)\n",
    "            centroids_idx = torch.LongTensor(algo.predict(points))\n",
    "            if hasattr(layer, 'bias'):\n",
    "                self.bias = torch.nn.Parameter(layer.bias)\n",
    "            else:\n",
    "                self.bias = None\n",
    "            \n",
    "        pad = torch.zeros(-len(centroids_idx) % self.code_size).long()\n",
    "        to_code = torch.cat([centroids_idx, pad]).view(-1, self.code_size)\n",
    "        \n",
    "        self.codes = torch.nn.Parameter(\n",
    "            torch.sum(to_code.long() * torch.LongTensor([(2 ** self.n_bits) ** i for i in range(self.code_size)]), dim=-1),\n",
    "                                        requires_grad=False) \n",
    "        self.codes_emb = torch.nn.Embedding.from_pretrained(centroids)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_):\n",
    "          decoded = self.codes.view(-1, 1) //\\\n",
    "                              torch.LongTensor([(2 ** self.n_bits) ** i for i in range(self.code_size)]).to(input_.device) %\\\n",
    "                              torch.LongTensor([(2 ** self.n_bits) for _ in range(self.code_size)]).to(input_.device)\n",
    "          decoded = decoded.view(-1)[:self.matrix_size.numel()]\n",
    "          weight = self.codes_emb(decoded)\n",
    "          weight = weight.view(self.matrix_size)\n",
    "          return torch.functional.F.linear(input_, weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHvET5fGVCdp"
   },
   "source": [
    "Without training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IQNVx5hH637g",
    "outputId": "d6dec958-0bc1-4fda-d5ca-e72d4a271a8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:29<00:00, 51.52s/it]\n"
     ]
    }
   ],
   "source": [
    "device = params['device']\n",
    "n_clusters = 4\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "irn8KesH8wJ6",
    "outputId": "7a7c6aaf-a788-4bfe-a8c5-f6f3f79f3aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.8555045871559633,\n",
       " 'eval_f1_score': 0.8545034642032333,\n",
       " 'eval_loss': 0.3484584675960824,\n",
       " 'eval_matthews_corrcoef': 0.7120853635082497}"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcbUFnkOVLoc"
   },
   "source": [
    "With training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEAL2zteCWW7"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Porr4FRlKkmI"
   },
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    [6, 3, 7,  8],\n",
    "    [4, 5, 0, 11],\n",
    "    [9, 2, 10, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "FN6B9asVKIBq",
    "outputId": "d1172153-7197-4a1f-d25c-3eac2d0ed227"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:25<00:00, 51.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2105/2105 [49:54<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.1246670034977291, 'train_global_step': 2105}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:16<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2155188312978989, 'eval_accuracy': 0.9151376146788991, 'eval_f1_score': 0.9174107142857143, 'eval_matthews_corrcoef': 0.8303008389339931}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.1246670034977291, 'train_global_step': 2105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:25<00:00, 50.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2105/2105 [46:07<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.07454932219837737, 'train_global_step': 2105}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24157569218345373, 'eval_accuracy': 0.9197247706422018, 'eval_f1_score': 0.9220489977728284, 'eval_matthews_corrcoef': 0.8395490166354784}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.07454932219837737, 'train_global_step': 2105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:19<00:00, 50.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2105/2105 [42:15<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.07110275359483625, 'train_global_step': 2105}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25014348505286876, 'eval_accuracy': 0.9151376146788991, 'eval_f1_score': 0.9185022026431717, 'eval_matthews_corrcoef': 0.8309517687830787}\n",
      "{'train_loss': 0.07110275359483625, 'train_global_step': 2105}\n"
     ]
    }
   ],
   "source": [
    "device = params['device']\n",
    "n_clusters = 4\n",
    "for i, block in enumerate(blocks):\n",
    "    for transformer_layer_ind in tqdm(block):\n",
    "        model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
    "\n",
    "        model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
    "\n",
    "\n",
    "        model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
    "\n",
    "\n",
    "        model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "        model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "        model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "        QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)\n",
    "\n",
    "    EPOCH_NUM = i\n",
    "\n",
    "    params['num_train_epochs'] = 1\n",
    "    checkpoint_files = {\n",
    "        'config': 'bert_config.json',\n",
    "        'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "            params['task_name'], EPOCH_NUM)\n",
    "    }\n",
    "\n",
    "    model, result = train(model, tokenizer, params,\n",
    "                          train_examples,\n",
    "                          valid_examples=dev_examples,\n",
    "                          checkpoint_files=checkpoint_files)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "LNwPEkXdwdrB",
    "outputId": "b53059a6-888d-4423-cb54-911d46b1b065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:19<00:00,  5.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.9151376146788991,\n",
       " 'eval_f1_score': 0.9185022026431717,\n",
       " 'eval_loss': 0.25014348505286876,\n",
       " 'eval_matthews_corrcoef': 0.8309517687830787}"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0CHjAT5wihk"
   },
   "outputs": [],
   "source": [
    "torch.save(model.bert.encoder.state_dict(), 'model-4-tr-enc.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4XtQbQTVqFh"
   },
   "source": [
    "8 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnKw67dfVt8y"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M4Ro_AtNB1Ed",
    "outputId": "aa2ffce7-27a7-46c6-f913-ae2a6fcbb3f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:31<00:00, 53.45s/it]\n"
     ]
    }
   ],
   "source": [
    "device = params['device']\n",
    "n_clusters = 8\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters).to(device)\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters).to(device)\n",
    "\n",
    "\n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBD2wev2CSgR"
   },
   "outputs": [],
   "source": [
    "torch.save(model.bert.encoder.state_dict(), 'model8_enc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "kz3483N4FT6H",
    "outputId": "81af6ea5-6844-4b4c-ef72-9ae7e69ece4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 843292\n",
      "-rw-r--r-- 1 root root 437982975 Apr  9 14:21 model.pt\n",
      "-rw-r--r-- 1 root root 340259226 Apr  9 16:55 model-all-enc.pt\n",
      "-rw-r--r-- 1 root root  32895719 Apr  9 17:11 model8_enc.pt\n",
      "-rw-r--r-- 1 root root  22456619 Apr  9 16:54 model4_enc.pt\n",
      "-rw-r--r-- 1 root root  22456619 Apr  9 16:54 model4.pt\n",
      "-rw-r--r-- 1 root root   7439277 May  2  2018 SST-2.zip\n",
      "drwxr-xr-x 6 root root      4096 Apr  9 14:20 lilbert\n",
      "drwxr-xr-x 1 root root      4096 Apr  4 20:20 sample_data\n",
      "drwxrwxr-x 3 root root      4096 May  2  2018 SST-2\n"
     ]
    }
   ],
   "source": [
    "!ls -lS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-hcwAPvWVv51",
    "outputId": "e4319663-1424-4ab9-b73f-f4af65340b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate of encoder, 8 clusters: 10.343571636175517\n",
      "Compression rate of encoder, 4 clusters: 15.151845698588911\n"
     ]
    }
   ],
   "source": [
    "print(\"Compression rate of encoder, 8 clusters: {}\".format(340259226 / 32895719))\n",
    "print(\"Compression rate of encoder, 4 clusters: {}\".format(340259226 / 22456619))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QuantArchitecture.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
