{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4298
    },
    "colab_type": "code",
    "id": "KlT-qAkyjniK",
    "outputId": "3abc2b5c-3812-42b5-d846-fada520c4414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "certifi",
         "dateutil",
         "decorator",
         "idna",
         "ipykernel",
         "numpy",
         "pandas",
         "prompt_toolkit",
         "pygments",
         "requests",
         "scipy",
         "six",
         "tornado",
         "urllib3",
         "zmq"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -O \"SST-2.zip\" 'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8'\n",
    "!unzip \"SST-2.zip\"\n",
    "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
    "    \n",
    "!pip install -r lilbert/requirements.txt\n",
    "!mkdir ./lilbert/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cAPMM5hMjueY",
    "outputId": "9dc92e6c-aeae-4b19-a6ad-0b946929f9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('lilbert/lilbert')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aZ7IGxMHjwWo",
    "outputId": "c0c91c6d-e454-4ebb-a553-fbd8d71c1e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f38e3e15190>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "params = {\n",
    "    'data_dir': 'SST-2',\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhnMoc8Gjx9v"
   },
   "outputs": [],
   "source": [
    "device = params['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CB6Rgf3Vj3-0"
   },
   "outputs": [],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "VBCX2HH_j5_O",
    "outputId": "8748d522-bca5-4db7-eeca-fa03b5acf9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-05 20:37:28--  https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/2gclpuhipfovph2/model_baseline_from_parts.pt [following]\n",
      "--2019-04-05 20:37:29--  https://www.dropbox.com/s/raw/2gclpuhipfovph2/model_baseline_from_parts.pt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com/cd/0/inline/AeezP0fXSZA-pvB1D8L5rzBgYNxkERs757-0yXPnqMSvFE9BW4gdSvrTAS3d0WnGH1kDlozB5ZhQ__bI6NS--TkOt7Go09o_ORHglehhaaC4-Q/file# [following]\n",
      "--2019-04-05 20:37:29--  https://uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com/cd/0/inline/AeezP0fXSZA-pvB1D8L5rzBgYNxkERs757-0yXPnqMSvFE9BW4gdSvrTAS3d0WnGH1kDlozB5ZhQ__bI6NS--TkOt7Go09o_ORHglehhaaC4-Q/file\n",
      "Resolving uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com (uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
      "Connecting to uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com (uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 437982975 (418M) [text/plain]\n",
      "Saving to: ‘model.pt’\n",
      "\n",
      "model.pt            100%[===================>] 417.69M  31.8MB/s    in 17s     \n",
      "\n",
      "2019-04-05 20:37:47 (24.4 MB/s) - ‘model.pt’ saved [437982975/437982975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C70Ag21Tj7jZ"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyCDrgAlkAEc"
   },
   "source": [
    "To reload initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKvLb3qEj8vY"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KW5aLlIQkq_3"
   },
   "source": [
    "Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vP_CADqOfZsG"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "class QuantizedLayer(torch.nn.Module):\n",
    "    def __init__(self, layer=None, n_clusters=8,  size=None):\n",
    "        super(QuantizedLayer, self).__init__()\n",
    "        if layer is None:\n",
    "            if size is None:\n",
    "                raise ValueError(\"During random init, size must be passed.\")\n",
    "            self.matrix_size = size\n",
    "            centroids = torch.randn(n_clusters).view(-1,1)\n",
    "            centroids_idx = torch.randint(low=0, high=n_clusters, size=size).view(1,-1).type(torch.ByteTensor)\n",
    "            self.bias=torch.nn.Parameter(torch.randn(size[0]))\n",
    "        else:\n",
    "            self.matrix_size = layer.weight.size()\n",
    "            algo = MiniBatchKMeans(n_clusters)\n",
    "            points = layer.weight.view(-1, 1).detach().cpu().numpy()\n",
    "            algo.fit(points)\n",
    "            centroids = torch.Tensor(algo.cluster_centers_)\n",
    "            centroids_idx = torch.ByteTensor(algo.predict(points))\n",
    "            self.bias = torch.nn.Parameter(layer.bias)\n",
    "\n",
    "        triplets = centroids_idx.view(-1, 2)\n",
    "        self.codes = torch.nn.Parameter(torch.sum(triplets * torch.ByteTensor([1, 8]),dim=-1).type(torch.uint8),\n",
    "                                        requires_grad=False)\n",
    "        self.emb = torch.nn.Embedding.from_pretrained(centroids)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_):\n",
    "          weight = self.emb((self.codes.view(-1, 1) //\\\n",
    "                              torch.ByteTensor([1, 8]).to(device) %\\\n",
    "                              torch.ByteTensor([8,8]).to(device)).view(-1).long())\n",
    "          weight = weight.view(self.matrix_size)\n",
    "          return torch.functional.F.linear(input_, weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4SLvxqPWhrg"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ID5mbAsAWOz6",
    "outputId": "d18046bf-9f98-4c38-c0eb-11525bbc80c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [09:39<00:00, 49.21s/it]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 8\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters)\n",
    "#     break\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBV1NV_gRear"
   },
   "outputs": [],
   "source": [
    "model = model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "vts2a4ADW4tD",
    "outputId": "4f17535b-a33d-44bf-a07c-acff97368c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20849375055802222,\n",
       " 'eval_accuracy': 0.9277522935779816,\n",
       " 'eval_f1_score': 0.9288135593220338,\n",
       " 'eval_matthews_corrcoef': 0.8554944362755638}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzKI1AaTW6iC"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_quant_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "m8VAdRG7_lEC",
    "outputId": "e0356849-e449-4247-a195-19497997d472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 572444\n",
      "-rw-r--r-- 1 root root 437982975 Apr  5 20:37 model.pt\n",
      "-rw-r--r-- 1 root root 140731981 Apr  5 20:52 model_quant_all.pt\n",
      "-rw-r--r-- 1 root root   7439277 May  2  2018 SST-2.zip\n",
      "drwxr-xr-x 6 root root      4096 Apr  5 19:35 lilbert\n",
      "drwxr-xr-x 1 root root      4096 Mar 27 20:26 sample_data\n",
      "drwxrwxr-x 3 root root      4096 May  2  2018 SST-2\n"
     ]
    }
   ],
   "source": [
    "!ls -lS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AIT2h9SQ_x3Q",
    "outputId": "87ae3f09-528d-4a4d-d758-04e6ca558e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.112177998830273"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "437982975 / 140731981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8cZspLrImV7"
   },
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I-MH0tXiFRkW",
    "outputId": "477f01ab-9db8-4cb6-92e5-03ec91d7a595"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "new_model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "n_clusters = 8\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.query.weight.size(), n_clusters=n_clusters)\n",
    "#     break\n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.key.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.value.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].output.dense.weight.size(), n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOL4Zgo6JUTG"
   },
   "outputs": [],
   "source": [
    "new_model.load_state_dict(torch.load('model_quant_all.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OteZK_9kSnwJ"
   },
   "outputs": [],
   "source": [
    "new_model=new_model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "lFn_pBaANHTq",
    "outputId": "1ee450e8-e1d1-4aed-8803-60a20cca596d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20849375055802222,\n",
       " 'eval_accuracy': 0.9277522935779816,\n",
       " 'eval_f1_score': 0.9288135593220338,\n",
       " 'eval_matthews_corrcoef': 0.8554944362755638}"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(new_model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "QuantArchitecture.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
