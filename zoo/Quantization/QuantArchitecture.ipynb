{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4298
    },
    "colab_type": "code",
    "id": "KlT-qAkyjniK",
    "outputId": "3abc2b5c-3812-42b5-d846-fada520c4414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-05 19:34:14--  https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\n",
      "Resolving firebasestorage.googleapis.com (firebasestorage.googleapis.com)... 74.125.203.95, 108.177.97.95, 74.125.204.95, ...\n",
      "Connecting to firebasestorage.googleapis.com (firebasestorage.googleapis.com)|74.125.203.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7439277 (7.1M) [application/zip]\n",
      "Saving to: ‘SST-2.zip’\n",
      "\n",
      "SST-2.zip           100%[===================>]   7.09M  36.7MB/s    in 0.2s    \n",
      "\n",
      "2019-04-05 19:34:16 (36.7 MB/s) - ‘SST-2.zip’ saved [7439277/7439277]\n",
      "\n",
      "Archive:  SST-2.zip\n",
      "   creating: SST-2/\n",
      "  inflating: SST-2/dev.tsv           \n",
      "   creating: SST-2/original/\n",
      "  inflating: SST-2/original/README.txt  \n",
      "  inflating: SST-2/original/SOStr.txt  \n",
      "  inflating: SST-2/original/STree.txt  \n",
      "  inflating: SST-2/original/datasetSentences.txt  \n",
      "  inflating: SST-2/original/datasetSplit.txt  \n",
      "  inflating: SST-2/original/dictionary.txt  \n",
      "  inflating: SST-2/original/original_rt_snippets.txt  \n",
      "  inflating: SST-2/original/sentiment_labels.txt  \n",
      "  inflating: SST-2/test.tsv          \n",
      "  inflating: SST-2/train.tsv         \n",
      "Cloning into 'lilbert'...\n",
      "remote: Enumerating objects: 143, done.\u001b[K\n",
      "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
      "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
      "remote: Total 143 (delta 58), reused 78 (delta 25), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (143/143), 403.80 KiB | 789.00 KiB/s, done.\n",
      "Resolving deltas: 100% (58/58), done.\n",
      "Requirement already satisfied: backcall==0.1.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: bleach==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 2)) (3.1.0)\n",
      "Collecting boto3==1.9.105 (from -r lilbert/requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/e3/0b36752f2634c214f433d0d3015d75b664bdd981669a7b2d15ae953f51af/boto3-1.9.105-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 3.7MB/s \n",
      "\u001b[?25hCollecting botocore==1.12.105 (from -r lilbert/requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/ce/acc9013dee20fc94c9b9ae121f5b7b342a206f0d577be1e5c6129811194a/botocore-1.12.105-py2.py3-none-any.whl (5.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.3MB 6.7MB/s \n",
      "\u001b[?25hCollecting certifi==2018.11.29 (from -r lilbert/requirements.txt (line 5))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/e0/accfc1b56b57e9750eba272e24c4dddeac86852c2bebd1236674d7887e8a/certifi-2018.11.29-py2.py3-none-any.whl (154kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 31.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 7)) (0.10.0)\n",
      "Collecting decorator==4.3.2 (from -r lilbert/requirements.txt (line 8))\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/cd/7c8240007e9716b14679bc217a1baefa4432aa30394f7e2ec40a52b1a708/decorator-4.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils==0.14 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 9)) (0.14)\n",
      "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 10)) (0.3)\n",
      "Collecting idna==2.8 (from -r lilbert/requirements.txt (line 11))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 22.3MB/s \n",
      "\u001b[?25hCollecting ipykernel==5.1.0 (from -r lilbert/requirements.txt (line 12))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f0be5c5ab335196f5cce96e5b889a4fcf5bfe462eb0acc05cd7e2caf65eb/ipykernel-5.1.0-py3-none-any.whl (113kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 31.7MB/s \n",
      "\u001b[?25hCollecting ipython==7.3.0 (from -r lilbert/requirements.txt (line 13))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3b/3fcf422a99a04ee493e6a4fc3014e3c8ff484a7feed238fef68bdc285085/ipython-7.3.0-py3-none-any.whl (768kB)\n",
      "\u001b[K    100% |████████████████████████████████| 778kB 24.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: jedi==0.13.3 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 15)) (0.13.3)\n",
      "Requirement already satisfied: Jinja2==2.10 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 16)) (2.10)\n",
      "Requirement already satisfied: jmespath==0.9.4 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 17)) (0.9.4)\n",
      "Requirement already satisfied: jsonschema==2.6.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 18)) (2.6.0)\n",
      "Requirement already satisfied: jupyter-client==5.2.4 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 19)) (5.2.4)\n",
      "Requirement already satisfied: jupyter-core==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 20)) (4.4.0)\n",
      "Requirement already satisfied: kiwisolver==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 21)) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 22)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 23)) (3.0.3)\n",
      "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 24)) (0.8.4)\n",
      "Collecting nbconvert==5.3.1 (from -r lilbert/requirements.txt (line 25))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/ea/280d6c0d92f8e3ca15fd798bbcc2ea141489f9539de7133d8fe10ea4b049/nbconvert-5.3.1-py2.py3-none-any.whl (387kB)\n",
      "\u001b[K    100% |████████████████████████████████| 389kB 26.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: nbformat==4.4.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 26)) (4.4.0)\n",
      "Collecting nltk==3.4 (from -r lilbert/requirements.txt (line 27))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 19.5MB/s \n",
      "\u001b[?25hCollecting notebook==5.7.4 (from -r lilbert/requirements.txt (line 28))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a6/dbdf0954d073ab2cf5421cad20334d1e4c780da37205c04522c045298f67/notebook-5.7.4-py2.py3-none-any.whl (9.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.0MB 5.9MB/s \n",
      "\u001b[?25hCollecting numpy==1.16.2 (from -r lilbert/requirements.txt (line 29))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 2.4MB/s \n",
      "\u001b[?25hCollecting pandas==0.24.1 (from -r lilbert/requirements.txt (line 30))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 5.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandocfilters==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 31)) (1.4.2)\n",
      "Requirement already satisfied: parso==0.3.4 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 32)) (0.3.4)\n",
      "Requirement already satisfied: pexpect==4.6.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 33)) (4.6.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 34)) (0.7.5)\n",
      "Requirement already satisfied: prometheus-client==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 35)) (0.6.0)\n",
      "Collecting prompt-toolkit==2.0.9 (from -r lilbert/requirements.txt (line 36))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
      "\u001b[K    100% |████████████████████████████████| 337kB 22.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 37)) (0.6.0)\n",
      "Collecting Pygments==2.3.1 (from -r lilbert/requirements.txt (line 38))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e5/6d710c9cf96c31ac82657bcfb441df328b22df8564d58d0c4cd62612674c/Pygments-2.3.1-py2.py3-none-any.whl (849kB)\n",
      "\u001b[K    100% |████████████████████████████████| 849kB 17.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 39)) (2.3.1)\n",
      "Collecting python-dateutil==2.8.0 (from -r lilbert/requirements.txt (line 40))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 28.7MB/s \n",
      "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.1 (from -r lilbert/requirements.txt (line 41))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 32.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz==2018.9 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 42)) (2018.9)\n",
      "Collecting pyzmq==18.0.0 (from -r lilbert/requirements.txt (line 43))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/5a/8ce70c20efaf78fac2524b2f8d98b7360c997bc11a748dd233f3add7507e/pyzmq-18.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 17.9MB/s \n",
      "\u001b[?25hCollecting regex==2019.2.21 (from -r lilbert/requirements.txt (line 44))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/b5/79b2b7d19a0e1f94f2b11e73ea9682a5bf9d78bcf25fb278955157acdf33/regex-2019.02.21.tar.gz (643kB)\n",
      "\u001b[K    100% |████████████████████████████████| 645kB 24.5MB/s \n",
      "\u001b[?25hCollecting requests==2.21.0 (from -r lilbert/requirements.txt (line 45))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 23.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: s3transfer==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 46)) (0.2.0)\n",
      "Collecting scikit-learn==0.20.2 (from -r lilbert/requirements.txt (line 47))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 8.4MB/s \n",
      "\u001b[?25hCollecting scipy==1.2.1 (from -r lilbert/requirements.txt (line 48))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.8MB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 49)) (1.5.0)\n",
      "Collecting singledispatch==3.4.0.3 (from -r lilbert/requirements.txt (line 50))\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl\n",
      "Collecting six==1.12.0 (from -r lilbert/requirements.txt (line 51))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting terminado==0.8.1 (from -r lilbert/requirements.txt (line 52))\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/20/a26211a24425923d46e1213b376a6ee60dc30bcdf1b0c345e2c3769deb1c/terminado-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: testpath==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 53)) (0.4.2)\n",
      "Requirement already satisfied: torch==1.0.1.post2 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 54)) (1.0.1.post2)\n",
      "Collecting tornado==5.1.1 (from -r lilbert/requirements.txt (line 55))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)\n",
      "\u001b[K    100% |████████████████████████████████| 522kB 17.1MB/s \n",
      "\u001b[?25hCollecting tqdm==4.31.1 (from -r lilbert/requirements.txt (line 56))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 19.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: traitlets==4.3.2 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 57)) (4.3.2)\n",
      "Collecting urllib3==1.24.1 (from -r lilbert/requirements.txt (line 58))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 31.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: wcwidth==0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 59)) (0.1.7)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r lilbert/requirements.txt (line 60)) (0.5.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.3.0->-r lilbert/requirements.txt (line 13)) (40.8.0)\n",
      "Building wheels for collected packages: nltk, regex, tornado\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9d/ef/31/0c507f6397ad4c57a5eeff89a089d1a6051eecee9dc0f9cb70\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325\n",
      "Successfully built nltk regex tornado\n",
      "\u001b[31mspacy 2.0.18 has requirement regex==2018.01.10, but you'll have regex 2019.2.21 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement notebook~=5.2.0, but you'll have notebook 5.7.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 5.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, six, python-dateutil, botocore, boto3, certifi, decorator, idna, prompt-toolkit, Pygments, ipython, tornado, ipykernel, nbconvert, singledispatch, nltk, pyzmq, terminado, notebook, numpy, pandas, regex, tqdm, requests, pytorch-pretrained-bert, scipy, scikit-learn\n",
      "  Found existing installation: urllib3 1.22\n",
      "    Uninstalling urllib3-1.22:\n",
      "      Successfully uninstalled urllib3-1.22\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: python-dateutil 2.5.3\n",
      "    Uninstalling python-dateutil-2.5.3:\n",
      "      Successfully uninstalled python-dateutil-2.5.3\n",
      "  Found existing installation: botocore 1.12.127\n",
      "    Uninstalling botocore-1.12.127:\n",
      "      Successfully uninstalled botocore-1.12.127\n",
      "  Found existing installation: boto3 1.9.127\n",
      "    Uninstalling boto3-1.9.127:\n",
      "      Successfully uninstalled boto3-1.9.127\n",
      "  Found existing installation: certifi 2019.3.9\n",
      "    Uninstalling certifi-2019.3.9:\n",
      "      Successfully uninstalled certifi-2019.3.9\n",
      "  Found existing installation: decorator 4.4.0\n",
      "    Uninstalling decorator-4.4.0:\n",
      "      Successfully uninstalled decorator-4.4.0\n",
      "  Found existing installation: idna 2.6\n",
      "    Uninstalling idna-2.6:\n",
      "      Successfully uninstalled idna-2.6\n",
      "  Found existing installation: prompt-toolkit 1.0.15\n",
      "    Uninstalling prompt-toolkit-1.0.15:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.15\n",
      "  Found existing installation: Pygments 2.1.3\n",
      "    Uninstalling Pygments-2.1.3:\n",
      "      Successfully uninstalled Pygments-2.1.3\n",
      "  Found existing installation: ipython 5.5.0\n",
      "    Uninstalling ipython-5.5.0:\n",
      "      Successfully uninstalled ipython-5.5.0\n",
      "  Found existing installation: tornado 4.5.3\n",
      "    Uninstalling tornado-4.5.3:\n",
      "      Successfully uninstalled tornado-4.5.3\n",
      "  Found existing installation: ipykernel 4.6.1\n",
      "    Uninstalling ipykernel-4.6.1:\n",
      "      Successfully uninstalled ipykernel-4.6.1\n",
      "  Found existing installation: nbconvert 5.4.1\n",
      "    Uninstalling nbconvert-5.4.1:\n",
      "      Successfully uninstalled nbconvert-5.4.1\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "  Found existing installation: pyzmq 17.0.0\n",
      "    Uninstalling pyzmq-17.0.0:\n",
      "      Successfully uninstalled pyzmq-17.0.0\n",
      "  Found existing installation: terminado 0.8.2\n",
      "    Uninstalling terminado-0.8.2:\n",
      "      Successfully uninstalled terminado-0.8.2\n",
      "  Found existing installation: notebook 5.2.2\n",
      "    Uninstalling notebook-5.2.2:\n",
      "      Successfully uninstalled notebook-5.2.2\n",
      "  Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "  Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "  Found existing installation: regex 2018.1.10\n",
      "    Uninstalling regex-2018.1.10:\n",
      "      Successfully uninstalled regex-2018.1.10\n",
      "  Found existing installation: tqdm 4.28.1\n",
      "    Uninstalling tqdm-4.28.1:\n",
      "      Successfully uninstalled tqdm-4.28.1\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "  Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "  Found existing installation: scikit-learn 0.20.3\n",
      "    Uninstalling scikit-learn-0.20.3:\n",
      "      Successfully uninstalled scikit-learn-0.20.3\n",
      "Successfully installed Pygments-2.3.1 boto3-1.9.105 botocore-1.12.105 certifi-2018.11.29 decorator-4.3.2 idna-2.8 ipykernel-5.1.0 ipython-7.3.0 nbconvert-5.3.1 nltk-3.4 notebook-5.7.4 numpy-1.16.2 pandas-0.24.1 prompt-toolkit-2.0.9 python-dateutil-2.8.0 pytorch-pretrained-bert-0.6.1 pyzmq-18.0.0 regex-2019.2.21 requests-2.21.0 scikit-learn-0.20.2 scipy-1.2.1 singledispatch-3.4.0.3 six-1.12.0 terminado-0.8.1 tornado-5.1.1 tqdm-4.31.1 urllib3-1.24.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "certifi",
         "dateutil",
         "decorator",
         "idna",
         "ipykernel",
         "numpy",
         "pandas",
         "prompt_toolkit",
         "pygments",
         "requests",
         "scipy",
         "six",
         "tornado",
         "urllib3",
         "zmq"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -O \"SST-2.zip\" 'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8'\n",
    "!unzip \"SST-2.zip\"\n",
    "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
    "    \n",
    "!pip install -r lilbert/requirements.txt\n",
    "!mkdir ./lilbert/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cAPMM5hMjueY",
    "outputId": "9dc92e6c-aeae-4b19-a6ad-0b946929f9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('lilbert/lilbert')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aZ7IGxMHjwWo",
    "outputId": "c0c91c6d-e454-4ebb-a553-fbd8d71c1e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f38e3e15190>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "params = {\n",
    "    'data_dir': 'SST-2',\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhnMoc8Gjx9v"
   },
   "outputs": [],
   "source": [
    "device = params['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CB6Rgf3Vj3-0"
   },
   "outputs": [],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "VBCX2HH_j5_O",
    "outputId": "8748d522-bca5-4db7-eeca-fa03b5acf9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-05 20:37:28--  https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/2gclpuhipfovph2/model_baseline_from_parts.pt [following]\n",
      "--2019-04-05 20:37:29--  https://www.dropbox.com/s/raw/2gclpuhipfovph2/model_baseline_from_parts.pt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com/cd/0/inline/AeezP0fXSZA-pvB1D8L5rzBgYNxkERs757-0yXPnqMSvFE9BW4gdSvrTAS3d0WnGH1kDlozB5ZhQ__bI6NS--TkOt7Go09o_ORHglehhaaC4-Q/file# [following]\n",
      "--2019-04-05 20:37:29--  https://uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com/cd/0/inline/AeezP0fXSZA-pvB1D8L5rzBgYNxkERs757-0yXPnqMSvFE9BW4gdSvrTAS3d0WnGH1kDlozB5ZhQ__bI6NS--TkOt7Go09o_ORHglehhaaC4-Q/file\n",
      "Resolving uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com (uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
      "Connecting to uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com (uc2f2886dba38b4c2cc320f3e590.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 437982975 (418M) [text/plain]\n",
      "Saving to: ‘model.pt’\n",
      "\n",
      "model.pt            100%[===================>] 417.69M  31.8MB/s    in 17s     \n",
      "\n",
      "2019-04-05 20:37:47 (24.4 MB/s) - ‘model.pt’ saved [437982975/437982975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C70Ag21Tj7jZ"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyCDrgAlkAEc"
   },
   "source": [
    "To reload initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKvLb3qEj8vY"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KW5aLlIQkq_3"
   },
   "source": [
    "Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vP_CADqOfZsG"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "class QuantizedLayer(torch.nn.Module):\n",
    "    def __init__(self, layer=None, n_clusters=8,  size=None):\n",
    "        super(QuantizedLayer, self).__init__()\n",
    "        if layer is None:\n",
    "            if size is None:\n",
    "                raise ValueError(\"During random init, size must be passed.\")\n",
    "            self.matrix_size = size\n",
    "            centroids = torch.randn(n_clusters).view(-1,1)\n",
    "            centroids_idx = torch.randint(low=0, high=n_clusters, size=size).view(1,-1).type(torch.ByteTensor)\n",
    "            self.bias=torch.nn.Parameter(torch.randn(size[0]))\n",
    "        else:\n",
    "            self.matrix_size = layer.weight.size()\n",
    "            algo = MiniBatchKMeans(n_clusters)\n",
    "            points = layer.weight.view(-1, 1).detach().cpu().numpy()\n",
    "            algo.fit(points)\n",
    "            centroids = torch.Tensor(algo.cluster_centers_)\n",
    "            centroids_idx = torch.ByteTensor(algo.predict(points))\n",
    "            self.bias = torch.nn.Parameter(layer.bias)\n",
    "\n",
    "        triplets = centroids_idx.view(-1, 2)\n",
    "        self.codes = torch.nn.Parameter(torch.sum(triplets * torch.ByteTensor([1, 8]),dim=-1).type(torch.uint8),\n",
    "                                        requires_grad=False)\n",
    "        self.emb = torch.nn.Embedding.from_pretrained(centroids)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_):\n",
    "          weight = self.emb((self.codes.view(-1, 1) //\\\n",
    "                              torch.ByteTensor([1, 8]).to(device) %\\\n",
    "                              torch.ByteTensor([8,8]).to(device)).view(-1).long())\n",
    "          weight = weight.view(self.matrix_size)\n",
    "          return torch.functional.F.linear(input_, weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4SLvxqPWhrg"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ID5mbAsAWOz6",
    "outputId": "d18046bf-9f98-4c38-c0eb-11525bbc80c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [09:39<00:00, 49.21s/it]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 8\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.query, n_clusters)\n",
    "#     break\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.key, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.self.value, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense, n_clusters)\n",
    "    \n",
    "    \n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(model.bert.encoder.layer[transformer_layer_ind].output.dense, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBV1NV_gRear"
   },
   "outputs": [],
   "source": [
    "model = model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "vts2a4ADW4tD",
    "outputId": "4f17535b-a33d-44bf-a07c-acff97368c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20849375055802222,\n",
       " 'eval_accuracy': 0.9277522935779816,\n",
       " 'eval_f1_score': 0.9288135593220338,\n",
       " 'eval_matthews_corrcoef': 0.8554944362755638}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzKI1AaTW6iC"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_quant_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "m8VAdRG7_lEC",
    "outputId": "e0356849-e449-4247-a195-19497997d472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 572444\n",
      "-rw-r--r-- 1 root root 437982975 Apr  5 20:37 model.pt\n",
      "-rw-r--r-- 1 root root 140731981 Apr  5 20:52 model_quant_all.pt\n",
      "-rw-r--r-- 1 root root   7439277 May  2  2018 SST-2.zip\n",
      "drwxr-xr-x 6 root root      4096 Apr  5 19:35 lilbert\n",
      "drwxr-xr-x 1 root root      4096 Mar 27 20:26 sample_data\n",
      "drwxrwxr-x 3 root root      4096 May  2  2018 SST-2\n"
     ]
    }
   ],
   "source": [
    "!ls -lS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AIT2h9SQ_x3Q",
    "outputId": "87ae3f09-528d-4a4d-d758-04e6ca558e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.112177998830273"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "437982975 / 140731981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8cZspLrImV7"
   },
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I-MH0tXiFRkW",
    "outputId": "477f01ab-9db8-4cb6-92e5-03ec91d7a595"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "new_model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])\n",
    "n_clusters = 8\n",
    "for transformer_layer_ind in tqdm(range(12)):\n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.query = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.query.weight.size(), n_clusters=n_clusters)\n",
    "#     break\n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.key = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.key.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.self.value = \\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.self.value.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].attention.output.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].intermediate.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.weight.size(), n_clusters=n_clusters)\n",
    "    \n",
    "    \n",
    "    new_model.bert.encoder.layer[transformer_layer_ind].output.dense =\\\n",
    "    QuantizedLayer(size=new_model.bert.encoder.layer[transformer_layer_ind].output.dense.weight.size(), n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOL4Zgo6JUTG"
   },
   "outputs": [],
   "source": [
    "new_model.load_state_dict(torch.load('model_quant_all.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OteZK_9kSnwJ"
   },
   "outputs": [],
   "source": [
    "new_model=new_model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "lFn_pBaANHTq",
    "outputId": "1ee450e8-e1d1-4aed-8803-60a20cca596d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:17<00:00,  6.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20849375055802222,\n",
       " 'eval_accuracy': 0.9277522935779816,\n",
       " 'eval_f1_score': 0.9288135593220338,\n",
       " 'eval_matthews_corrcoef': 0.8554944362755638}"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(new_model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "QuantArchitecture.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
