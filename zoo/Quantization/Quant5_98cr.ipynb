{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cYnxR10hK_4J",
    "outputId": "2174a289-410d-477e-eff0-051915cbab25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sYVqYCsb1r9M",
    "outputId": "67a8d022-c493-4392-f5f0-e613843494c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.7\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DhovDXZNb6lU",
    "outputId": "519e427a-cade-491b-b96c-eb39e725467c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4227
    },
    "colab_type": "code",
    "id": "DHnSCboqov2D",
    "outputId": "3d28d8ec-9748-4e2f-a905-4e4bf5434ddf"
   },
   "outputs": [],
   "source": [
    "!wget -O \"SST-2.zip\" \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\"\n",
    "!unzip \"SST-2.zip\"\n",
    "# заменить username и password на свои \n",
    "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
    "    \n",
    "!pip install -r lilbert/requirements.txt\n",
    "!mkdir ./lilbert/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q9y6wpZbnAHe",
    "outputId": "96237657-c3c8-4349-d421-f8acfeaf35d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('lilbert/lilbert')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "83Bkz04EnAHk",
    "outputId": "9329804e-7905-4eea-e530-f7158369a2b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f48b8ad1f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "params = {\n",
    "    'data_dir': 'SST-2',\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7A_69kAP7FEg"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "L184y_u8y7pT",
    "outputId": "b4920518-9318-4ec4-e71b-2ef9744b0d0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 413241.10B/s]\n",
      "100%|██████████| 407873900/407873900 [00:31<00:00, 12818917.85B/s]\n"
     ]
    }
   ],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "p9E_z1Vk37jM",
    "outputId": "d2646169-fd98-4c97-bb76-b68de349f643"
   },
   "outputs": [],
   "source": [
    "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tHiMZ_M46Jr"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "cwLWt7E4nAH8",
    "outputId": "bb6cd80b-fa86-4379-edca-57343b5fc20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:14<00:00,  7.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.9254587155963303,\n",
       " 'eval_f1_score': 0.9276974416017797,\n",
       " 'eval_loss': 0.19265737580421163,\n",
       " 'eval_matthews_corrcoef': 0.851069468488703}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBS0DSjd5Nvr"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "class Clusterize():\n",
    "    def __init__(self, matrix, num_clusters=10):\n",
    "      # reshape matrix\n",
    "        self.matrix_shape = matrix.shape\n",
    "        self.matrix = matrix.reshape((-1,1))\n",
    "        matrix_len = len(self.matrix)\n",
    "        # clustering\n",
    "        cluster_algo = KMeans(n_clusters=num_clusters)\n",
    "        cluster_algo.fit(self.matrix)\n",
    "        self.clusters_labels = cluster_algo.labels_\n",
    "        self.centers = cluster_algo.cluster_centers_\n",
    "        # sort by vars\n",
    "        self.clusters_size = [sum(self.clusters_labels == n_cluster) for n_cluster in range(num_clusters)]\n",
    "        self.cluster_EQ = [self.matrix[np.argwhere(self.clusters_labels == n_cluster), :].var() * self.clusters_size[n_cluster]\n",
    "            for n_cluster in range(num_clusters)]\n",
    "      \n",
    "    def get_clustered_matrix(self, num_clusters_to_quant=1):\n",
    "\n",
    "        to_quant = np.argsort(self.cluster_EQ)[-num_clusters_to_quant:]\n",
    "        # quantize\n",
    "        mask = np.ones_like(self.clusters_labels)\n",
    "        for n_cluster in to_quant:\n",
    "            self.matrix[np.argwhere(self.clusters_labels == n_cluster), :] = self.centers[n_cluster][0]\n",
    "            mask[np.argwhere(self.clusters_labels == n_cluster)] = 0\n",
    "        return self.matrix.reshape(self.matrix_shape), mask.reshape(self.matrix_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whcz-f2lc9F2"
   },
   "source": [
    "### Embedding quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZBl9upvqEBQ"
   },
   "outputs": [],
   "source": [
    "class QuantLayerByteEmb(torch.nn.Module):\n",
    "    def __init__(self, quant_matrix):\n",
    "        super(QuantLayerByteEmb, self).__init__()\n",
    "        self.values = torch.unique(quant_matrix)\n",
    "        indx = [torch.nonzero(quant_matrix == value) for value in self.values]\n",
    "        vals = [torch.ones(ind.shape[0]).to(device) * value for ind, value in zip(indx, self.values)]\n",
    "        self.spmatrix = torch.sparse.FloatTensor(torch.cat(indx).transpose(dim0=1, dim1=0),\n",
    "                                                 torch.cat(vals),\n",
    "                                                 quant_matrix.shape)\n",
    "    def forward(self, x):\n",
    "        return torch.functional.F.embedding(x, self.spmatrix.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qV0fKmdqreM"
   },
   "outputs": [],
   "source": [
    "clusters = Clusterize(model.bert.embeddings.word_embeddings.weight.cpu().data, 5)\n",
    "quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "model.bert.embeddings.word_embeddings = QuantLayerByteEmb(quant_matrix.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tudXvsL1VmWJ"
   },
   "source": [
    "### Linear layers quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxZ0MSGWqdTz"
   },
   "outputs": [],
   "source": [
    "class QuantLayerByte(torch.nn.Module):\n",
    "    def __init__(self, quant_matrix, bias=None):\n",
    "        super(QuantLayerByte, self).__init__()\n",
    "        self.values = torch.unique(quant_matrix)\n",
    "        self.bias = bias\n",
    "        indx = [torch.nonzero(quant_matrix == value) for value in self.values]\n",
    "        vals = [torch.ones(ind.shape[0]).to(device) * value for ind, value in zip(indx, self.values)]\n",
    "        self.spmatrix = torch.sparse.FloatTensor(torch.cat(indx).transpose(dim0=1, dim1=0),\n",
    "                                                 torch.cat(vals),\n",
    "                                                 quant_matrix.shape)\n",
    "    def forward(self, x):\n",
    "        return torch.functional.F.linear(x, self.spmatrix.to_dense(), self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIS-utj9rHVU"
   },
   "source": [
    "Quantization of the last 6 transformer layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lElPa69TZmT_",
    "outputId": "549c11fb-5a8a-45a0-d3aa-4d9ecee79a43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [23:47<00:00, 236.62s/it]\n"
     ]
    }
   ],
   "source": [
    "for transformer_layer_ind in tqdm(range(6,12)):\n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.self.query.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.query.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    clusters = Clusterize(    model.bert.encoder.layer[transformer_layer_ind].attention.self.key.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.key.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.self.value.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.value.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].output.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].output.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense = QuantLayerByte(quant_matrix.to(device), bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two epoches training after quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "djkunK171aeQ",
    "outputId": "7ab76f86-627d-47e1-b88a-f919f204586f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2105/2105 [58:20<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.12293930361290725, 'train_global_step': 2105}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:52<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2178882598109006, 'eval_accuracy': 0.9174311926605505, 'eval_f1_score': 0.9198218262806236, 'eval_matthews_corrcoef': 0.834957173451512}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_global_step': 2105, 'train_loss': 0.12293930361290725}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 1\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "zIihwiwGJwH8",
    "outputId": "e7014dd0-3077-48b1-9fb0-33330b3d23be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 2105/2105 [58:06<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.05766299047248522, 'train_global_step': 2105}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:52<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25082281055555034, 'eval_accuracy': 0.9185779816513762, 'eval_f1_score': 0.9211986681465039, 'eval_matthews_corrcoef': 0.8373848900015683}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_global_step': 2105, 'train_loss': 0.05766299047248522}"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_NUM = 2\n",
    "\n",
    "params['num_train_epochs'] = 1\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhunNCVHqNiT"
   },
   "source": [
    "Quantization of the first 6 layers of transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmqEvmc6W9wE",
    "outputId": "15901d52-6d71-4db4-bfb5-721659a72229"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [24:21<00:00, 243.80s/it]\n"
     ]
    }
   ],
   "source": [
    "for transformer_layer_ind in tqdm(range(6)):\n",
    "  \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.self.query.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.query.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.query = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.self.key.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.key.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.key = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.self.value.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.self.value.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.self.value = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].attention.output.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].attention.output.dense = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].intermediate.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].intermediate.dense = QuantLayerByte(quant_matrix.to(device), bias)\n",
    "    \n",
    "    \n",
    "    clusters = Clusterize(model.bert.encoder.layer[transformer_layer_ind].output.dense.weight.cpu().data, 5)\n",
    "    quant_matrix, _ = clusters.get_clustered_matrix(5)\n",
    "    bias = model.bert.encoder.layer[transformer_layer_ind].output.dense.bias\n",
    "    model.bert.encoder.layer[transformer_layer_ind].output.dense = QuantLayerByte(quant_matrix.to(device), bias)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "wO4YWrShHyCc",
    "outputId": "35e19533-79ed-45d4-9fa9-f8f47f3ad923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [01:18<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.9105504587155964,\n",
       " 'eval_f1_score': 0.9129464285714285,\n",
       " 'eval_loss': 0.24320432879693551,\n",
       " 'eval_matthews_corrcoef': 0.8211187974949624}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qe4gotTJtG53"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_quant_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "8-ZV5LJ2tIQK",
    "outputId": "997942e5-6868-45bb-8bdf-a1181bbd825e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 439376\n",
      "-rw-r--r-- 1 root root 437982975 Mar 29 23:03 model.pt\n",
      "-rw-r--r-- 1 root root   7439277 May  2  2018 SST-2.zip\n",
      "-rw-r--r-- 1 root root   4467526 Mar 30 02:04 model_quant_all.pt\n",
      "drwxr-xr-x 6 root root      4096 Mar 29 23:02 lilbert\n",
      "drwxr-xr-x 1 root root      4096 Mar 27 20:26 sample_data\n",
      "drwxrwxr-x 3 root root      4096 May  2  2018 SST-2\n"
     ]
    }
   ],
   "source": [
    "! ls -lS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SPJKeQ5mq-Fu",
    "outputId": "23e46dc5-516e-4ce5-e106-42085083c8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate: 98.03702877162885\n"
     ]
    }
   ],
   "source": [
    "print(\"Compression rate:\", 437982975 / 4467526)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-j35b_Oe-9z"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('model_quant_all.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Quant5_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
