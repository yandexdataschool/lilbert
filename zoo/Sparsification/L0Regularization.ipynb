{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from lib import data_processors, tasks\n",
    "from lib.bert import BertForSequenceClassification\n",
    "from lib.train_eval import train, evaluate, predict\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcb5571a6f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "params = {\n",
    "    'data_dir': '../../../data/SST-2', # changed\n",
    "    'output_dir': '../output',\n",
    "    'cache_dir': '../model_cache',\n",
    "    'task_name': 'sst2',\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'max_seq_length': 128,\n",
    "    'train_batch_size': 12,\n",
    "    'eval_batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'num_train_epochs': 1,\n",
    "    'seed': 1331,\n",
    "    'device': torch.device(\n",
    "        'cuda' if torch.cuda.is_available()\n",
    "        else 'cpu')\n",
    "}\n",
    "\n",
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "torch.manual_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.l0reg.modules import L0LinearWrapper, L0Linear, L0Conv2dWrapper, L0Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def l0_wrapper(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        return L0LinearWrapper(layer)\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        return L0Conv2dWrapper(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l0_wrap_bert_layer(bert_layer):\n",
    "    bert_layer.attention.self.query = l0_wrapper(bert_layer.attention.self.query)\n",
    "    bert_layer.attention.self.key = l0_wrapper(bert_layer.attention.self.key)\n",
    "    bert_layer.attention.self.value = l0_wrapper(bert_layer.attention.self.value)\n",
    "    bert_layer.attention.output.dense = l0_wrapper(bert_layer.attention.output.dense)\n",
    "    bert_layer.intermediate.dense = l0_wrapper(bert_layer.intermediate.dense)\n",
    "    bert_layer.output.dense = l0_wrapper(bert_layer.output.dense)\n",
    "    return bert_layer\n",
    "\n",
    "def l0_penalty_bert_layer(bert_layer):\n",
    "    penalty = bert_layer.attention.self.query.penalty\n",
    "    penalty += bert_layer.attention.self.key.penalty\n",
    "    penalty += bert_layer.attention.self.value.penalty\n",
    "    penalty += bert_layer.attention.output.dense.penalty\n",
    "    penalty += bert_layer.intermediate.dense.penalty\n",
    "    penalty += bert_layer.output.dense.penalty\n",
    "    return penalty\n",
    "\n",
    "def num_zeroed(l0_linear_layer):\n",
    "    return (l0_linear_layer._get_mask()[0].cpu().data.numpy() == 0).sum()\n",
    "\n",
    "def num_zeroed_bert_layer(bert_layer):\n",
    "    n = num_zeroed(bert_layer.attention.self.query)\n",
    "    n += num_zeroed(bert_layer.attention.self.key)\n",
    "    n += num_zeroed(bert_layer.attention.self.value)\n",
    "    n += num_zeroed(bert_layer.attention.output.dense)\n",
    "    n += num_zeroed(bert_layer.intermediate.dense)\n",
    "    n += num_zeroed(bert_layer.output.dense)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertL0Encoder(nn.Module):\n",
    "    def __init__(self, bert_encoder):\n",
    "        super(BertL0Encoder, self).__init__()\n",
    "        self.l0_indices = [11]\n",
    "        self.encoder = bert_encoder\n",
    "        for i in self.l0_indices:\n",
    "            self.encoder.layer[i] = l0_wrap_bert_layer(self.encoder.layer[i])\n",
    "    \n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        penalty = 0\n",
    "        for i, layer_module in enumerate(self.encoder.layer):\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)\n",
    "            if i in self.l0_indices:\n",
    "                penalty += l0_penalty_bert_layer(layer_module)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "        return all_encoder_layers, penalty\n",
    "    \n",
    "    def num_zeroed(self):\n",
    "        n = 0\n",
    "        for i in self.l0_indices:\n",
    "            n += num_zeroed_bert_layer(self.encoder.layer[i])\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertL0Model(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(BertL0Model, self).__init__()\n",
    "        self.model = bert_model\n",
    "        self.model.encoder = BertL0Encoder(self.model.encoder)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        extended_attention_mask = extended_attention_mask.to(\n",
    "            dtype=next(self.model.parameters()).dtype) # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.model.embeddings(input_ids, token_type_ids)\n",
    "        encoded_layers, penalty = self.model.encoder(\n",
    "            embedding_output,\n",
    "            extended_attention_mask,\n",
    "            output_all_encoded_layers=output_all_encoded_layers\n",
    "        )\n",
    "        sequence_output = encoded_layers[-1]\n",
    "        pooled_output = self.model.pooler(sequence_output)\n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "        return encoded_layers, pooled_output, penalty\n",
    "    \n",
    "    def num_zeroed(self):\n",
    "        return self.model.encoder.num_zeroed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from lib.bert import BertForSequenceClassification\n",
    "\n",
    "class BertL0ForSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config, num_labels, l0=1):\n",
    "        super(BertL0ForSequenceClassification, self).__init__(config, num_labels)\n",
    "        self.l0 = l0\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path,\n",
    "                        l0=1, state_dict=None, cache_dir=None,\n",
    "                        from_tf=False, *inputs, **kwargs):\n",
    "        model = super(BertL0ForSequenceClassification, cls).from_pretrained(\n",
    "            pretrained_model_name_or_path, state_dict=state_dict,\n",
    "            cache_dir=cache_dir, from_tf=from_tf, *inputs, **kwargs)\n",
    "        model.l0 = l0\n",
    "        return model\n",
    "    \n",
    "    def wrap(self):\n",
    "        self.bert = BertL0Model(self.bert)\n",
    "        return self\n",
    "    \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output, penalty = self.bert(\n",
    "            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1)) + self.l0 * penalty\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def num_zeroed(self):\n",
    "        return self.bert.num_zeroed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
    "params['label_list'] = tasks.label_lists[params['task_name']]\n",
    "\n",
    "processor = tasks.processors[params['task_name']]()\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    params['bert_model'], do_lower_case=True)\n",
    "\n",
    "train_examples = processor.get_train_examples(params['data_dir'])\n",
    "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
    "model = BertL0ForSequenceClassification.from_pretrained(\n",
    "    params['bert_model'],\n",
    "    cache_dir=params['cache_dir'],\n",
    "    num_labels=params['num_labels']).wrap().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.data import (\n",
    "    DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.modeling import BertConfig\n",
    "\n",
    "from lib import feature_processors, metrics\n",
    "from lib.bert import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def train(model, tokenizer, params,\n",
    "          train_examples,\n",
    "          valid_examples=None,\n",
    "          checkpoint_files={'config': 'bert_config.json',\n",
    "                            'model_weigths': 'model_trained.pth'}):\n",
    "    global DANCING\n",
    "    \n",
    "    random.seed(params['seed'])\n",
    "    np.random.seed(params['seed'])\n",
    "    torch.manual_seed(params['seed'])\n",
    "    \n",
    "    train_steps_per_epoch = int(len(train_examples) / params['train_batch_size'])\n",
    "    num_train_optimization_steps = train_steps_per_epoch * params['num_train_epochs']\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer\n",
    "                    if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer\n",
    "                    if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=params['learning_rate'],\n",
    "                         warmup=params['warmup_proportion'],\n",
    "                         t_total=num_train_optimization_steps)\n",
    "    \n",
    "    global_step = 0\n",
    "    nb_tr_steps = 0\n",
    "    tr_loss = 0\n",
    "    \n",
    "    train_features = feature_processors.convert_examples_to_features(\n",
    "        train_examples,\n",
    "        params['label_list'],\n",
    "        params['max_seq_length'],\n",
    "        tokenizer)\n",
    "    print(\"***** Running training *****\")\n",
    "    print(\"Num examples:\",  len(train_examples))\n",
    "    print(\"Batch size:  \", params['train_batch_size'])\n",
    "    print(\"Num steps:   \", num_train_optimization_steps)\n",
    "    all_input_ids = torch.tensor(\n",
    "        [f.input_ids for f in train_features],\n",
    "         dtype=torch.long)\n",
    "    all_input_mask = torch.tensor(\n",
    "        [f.input_mask for f in train_features],\n",
    "         dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor(\n",
    "        [f.segment_ids for f in train_features],\n",
    "         dtype=torch.long)\n",
    "    all_label_ids = torch.tensor(\n",
    "        [f.label_id for f in train_features],\n",
    "         dtype=torch.long)\n",
    "    train_data = TensorDataset(all_input_ids,\n",
    "                               all_input_mask,\n",
    "                               all_segment_ids,\n",
    "                               all_label_ids)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler,\n",
    "        batch_size=params['train_batch_size'])\n",
    "\n",
    "    model.train()\n",
    "    for epoch_num in range(int(params['num_train_epochs'])):\n",
    "        print('\\nEpoch: {}'.format(epoch_num + 1))\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
    "            batch = tuple(t.to(params['device']) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            loss.backward()\n",
    "            \n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        train_result = {\n",
    "            'train_loss': tr_loss / nb_tr_steps,\n",
    "            'train_global_step': global_step,\n",
    "        }\n",
    "        print(train_result)\n",
    "        if valid_examples is not None:\n",
    "            valid_result, valid_prob_preds = evaluate(\n",
    "                model, tokenizer, params, valid_examples)\n",
    "            print('0s:', model.num_zeroed())\n",
    "            print('min:',\n",
    "                  model.bert.model.encoder.encoder.layer[11].attention.self.key._get_mask()[0].min())\n",
    "            DANCING.append(\n",
    "                (model.num_zeroed(),\n",
    "                 model.bert.model.encoder.encoder.layer[11].attention.self.key._get_mask()[0].min(),\n",
    "                 valid_result))\n",
    "            print(valid_result)\n",
    "            model.train()\n",
    "\n",
    "    if not os.path.exists(params['output_dir']):\n",
    "        os.makedirs(params['output_dir'])\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    output_model_file = os.path.join(params['output_dir'],\n",
    "                                     checkpoint_files['file_to_save'])\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    output_config_file = os.path.join(params['output_dir'],\n",
    "                                      checkpoint_files['config'])\n",
    "    with open(output_config_file, 'w') as f:\n",
    "        f.write(model_to_save.config.to_json_string())\n",
    "\n",
    "    train_result = {\n",
    "        'train_loss': tr_loss / nb_tr_steps,\n",
    "        'train_global_step': global_step,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return model, train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l0 = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   12\n",
      "Num steps:    56120\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23a43dcdccb4be59ed513716318ecdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ae701fb0ab4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                       \u001b[0mvalid_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                       checkpoint_files=checkpoint_files)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5106b92246f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, params, train_examples, valid_examples, checkpoint_files)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ab1e8a6ac846>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         _, pooled_output, penalty = self.bert(\n\u001b[0;32m---> 25\u001b[0;31m             input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ca7d654fb313>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b442b7280400>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml0_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mpenalty\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml0_penalty_bert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 10\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4302.9189453125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated() / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_elem = [\n",
    "    0.4678, 0.4394, 0.4164, 0.3934, 0.38, 0.3613, 0.345, 0.34, 0.3378, 0.315,\n",
    "    0.306, 0.2947, 0.2746, 0.2546, 0.24105, 0.2275, 0.2183, 0.212, 0.2081, 0.2068,\n",
    "    0.1938, 0.1734, 0.1563, 0.1421, 0.1305, 0.1214, 0.1145, 0.1097, 0.1069, 0.1059\n",
    "]\n",
    "for _, m, _ in DANCING:\n",
    "    min_elem.append(float(m.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24105"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.2546 + 0.2275) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAF2CAYAAABUN1CyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOX5xvH7yZ6QjRAIhLCEfQcBAQFxV1zR4l530brQYq11qW21trVutS51rQvWDa173bCiKIqsISEkhIRACFlICEkIIetk3t8fmfjLwUASmHnPzHvuz3VxyUwmZ5755sibM5mcEaUUiIiIyH8E2T0AERERWXFxJiIi8jNcnImIiPwMF2ciIiI/w8WZiIjIz3BxJiIi8jNcnMnRROReEdlkyv34IxGZJyJ5IuISkcV2z9NGRI4XESUiiXbPQnQgLs5kFBFZ7PkH98UOPvag52Mft7v6EQDH6ZswMIhIgYjc5qXNvQjgXQCDACzy0jaJjMbFmUy0E8CFItKj7QoRCQFwBYDC9jdUStUqpfZons8xRCQeQC8AS5VSxUqpvXbPRBQIuDiTiTYCyANwYbvrzgTQAGB5+xse+HSz58j7YxFZJCLFIlIlIi+LSNSh7lBExojIJyKyT0TKReRNEenbyedcLSLZItIgIrki8msRCWr3cSUiN4rIhyJS57nNCSKSIiJLRWS/iKSLyOQDtjtTRL7xfE6xiDwjIrHtPr5cRJ4WkftFpMIz7yNt9y0iy9F6lPuwZ4aDnkZQRHqKyCueTvUi8qWIjPV87HgAVZ6bfuXZ1vEH2U6BiPzR03+fiOwUkYtEJF5ElohIreep8VPbfU6wiLwoIts9950nIrcf0HC8iCwTkRrPNjJE5ISDzBAuIu+LSJqI9DnYYybSgYszmepFANe0u3wNgJcBdOV8tccCGAfgZAAXATgPh3g6VkT6AfgWwCYA0zyfFw3gw/YLxQGfcx2A+wH8EcBoAL8BcAeAmw646e8BLAEwEcA6z99fBPA0gKMAlABY3G674wF8AeAjz+f8DMAkAC8dsN2fA3ABmAlgIYBbPI8Vns8pAnAfgH6ePwezGMB0APM8j70OwOciEglgJYCxntvN92xn5SG2dQuANQAmA3gbwCsA3gDwqecxfAvgNRGJ8Nw+CEAxWr8JGw3gbgC/A3B1u22+AaDUM9skAPei9Zs0C883L58DSABwvFKq/BBzEvmeUop/+MeYP2hdLD4G0BNAPYDhAPoCaAQwsO3j7W5/L4BNB3z+TgDB7a77F4AvD3Gf9wFYdsB1PdH6jcC0g9xPIYDLD/icWwBkt7usAPyt3eVxnutubXfd8Z7rEj2X/w3gxQO2O8lzmz6ey8sB/HDAbf4H4IV2lwsA3NZJ6+Ge7c5pd10cgL0AFnguJ3puc3wn2yoA8Ga7y9Gez3ui3XWDPddNPcR2Hmj/tQJQA+DKg9y2rd0YAOvR+g1NhN37MP/wj1IKIR2s10QBTylVJSLvo/WIuRrAcqVUoYh05dOzlVIt7S6XoPXo8GCmAJgjIrUdfGwoWo8GfyQivQEMAPCciDzT7kMhAA4ccGO7v5d5/pvZwXV9AFR4ZhkmIhe1u03bNocCaDsibL9doPUxdvep3NEA3AB+aLtCKbVXRDLRuuB1148zKaVqRaQOB3+sAAARuQHAArQ+DR8JIBTAjnaf8yiAF0TkSgDLALyrlMo54H6XAkgDMF8p5TqMuYm8joszmewltD41WovWp4+7qvmAywqH/hFQEIBPAHT06uayDq5r29YNOPTTvAfOog5xXVC7/74A4B8dbKv4INtt2443f8x1OG9319FMB32snm9AHkNr95VoPUq+Ga0/hmj9BKXuFZHXAZwO4DQA94jIDUqp9k/zf4zWp8bHAUg/jLmJvI6LM5lsGYAmtD61+oEP7ycNrf+471BKHbjA/IRSqkxESgAMVUr92wezjFVKbT3C7TQBCO7kNpvRulAeg9afB7f97HY8Wn++72uzAaxWSv2z7QoRGXrgjZRSeWh9geATnmcqFsD6M/g/AKgEsExETlJKcYEm2/EFYWQspZQCMAFAqlKq0Yd39RRaf9b6lohMF5EhInKyiDwvIjEH+Zx7ANzueYX2SBEZJyJXiMhdRzjLgwCmicizInKUiAwTkbNE5LlubqcAwLEi0l8OcpIOz6L3IVqfnj/W82K019B6BPvGETyGrsoFMFlETheR4SLyB7T7nXURiRSRp6T1ZCODRWQ6Whf07A4ey90AngPwpYhM1DA70SFxcSajKaX2KaVqfHwfJQBmofXnr58DyELrgt3o+dPR57yA1p+HXw4gA8AKANcD2H6Es2wEMAetL576xrPtv6Hjp9cP5Y9o/bl4PoDdh7jd1Wj9mfpHnv9GAZirlKrv5v0djufQ+qruNwCsRetj/nu7j7eg9YV5iwFsAfA+Wn8+fmtHG1NK/Q6tL/5bxgWa7CatBxdERETkL3jkTERE5Ge4OBMREfkZLs5ERER+hoszERGRn+HiTERE5GdsOwlJYmKiGjx4sF13T0REpNX69esrlFK9u3Jb2xbnwYMHY926dV7bXnZ2NsaMOZzT+dLhYnO92Fsv9tbLCb1FZEfnt2plzNPaqampdo/gOGyuF3vrxd56sbeVMYtzSUmJ3SM4Dpvrxd56sbde7G1lzOKckJBg9wiOw+Z6sbde7K0Xe1sZszjX1dXZPYLjsLle7K0Xe+vF3lbGLM5BQcY8lIDB5nqxt17srRd7WxlTIzQ01O4RHIfN9WJvvdhbL/a2MmZxrq2ttXsEx2FzvdhbL/bWi72tjFmcExM7fD948iE214u99WJvvdjbypjFuaioyO4RHIfN9WJvvdhbL/a2MmZxHjZsmN0jOA6b68XeerG3XuxtZczinJWVZfcIjsPmerG3XuytF3tbGbE41ze1oEj62D2G40ycONHuERyFvfVib73Y28qIxfmNNYW4+Y00rN9RafcojrJ+/Xq7R3AU9taLvfVibytRStlyx1OnTlXeelequiYX5jz0NUYkxeCN62Z4ZZtERETeJCLrlVJTu3JbI46co8JCcPbQcKzM34Mf8vfYPY5j8DtdvdhbL/bWi72tjDhyBoCG5hYc9/DXGJgQhbd/cQxExGvbJiIiOlKOO3IGgLycbCw8YRjWFlTh27wKu8dxhMzMTLtHcBT21ou99WJvK2MW5xEjRuDCowegf3wkHv1iC+x6RsBJRowYYfcIjsLeerG3XuxtZcziXFhYiPCQYPzyxGHIKNqLZZvL7R7JeIWFhXaP4CjsrRd768XeVsYszklJSQCA+VNSMKhXFB79Xy7cbh49+1Jbc9KDvfVib73Y28qYxbm6uhoAEBochEUnDUd2aQ2WZu2yeSqztTUnPdhbL/bWi72tjFmcIyIifvz7vEn9MbR3D/zjy1y08OjZZ9o3J99jb73YWy/2tjJmcW4vOEhwy8kjkFtWi483ltg9DhERUbcYszg3NDRYLp85vh9G9Y3BY1/mwdXitmkqsx3YnHyLvfVib73Y28qYxTk+Pt5yOchz9Ly9Yj/e31Bs01RmO7A5+RZ768XeerG3lTGLc1lZ2U+uO21sEsb1j8UTX+WhmUfPXtdRc/Id9taLvfVibytjFueBAwf+5DoRwW9OGYmdlfX4z7oiG6YyW0fNyXfYWy/21ou9rYxZnHNzczu8/viRvXHUwHg8+VUeGppbNE9ltoM1J99gb73YWy/2tjJmcR4/fnyH17cdPZfubcCSNTwDjTcdrDn5Bnvrxd56sbeVMYvzod5ubNawXpiWmoCnluejvolHz97Ct3jTi731Ym+92NvKmLeM7Mya7ZW48LkfsOik4fj1KTzBOhER6eXIt4zs7LuuaakJmDcpGc8sz8fW8n2apjIbv9PVi731Ym+92NvKMUfOAFBR24iT/v4NRibFYMn1MxAUJFrvn4iInMuRR84ZGRmd3iYxOhx3nzkaawoq8da6nRqmMltXmpP3sLde7K0Xe1sZc+TscrkQEhLS6e2UUrjkX6uQVVKDZbcehz6xPNn64epqc/IO9taLvfVyQm9HHjlv3bq1S7cTEdx/3ng0utz408fZPp7KbF1tTt7B3nqxt17sbWXM4pySktLl2w7pHY1fnjAMn2wsxbLNPGXc4epOczpy7K0Xe+vF3lbGLM4VFRXduv0vjhuK4X2i8YcPNmF/o8tHU5mtu83pyLC3XuytF3tbGbM4R0dHd+v2YSFBeGD+eJTsbcDfv+Bp4w5Hd5vTkWFvvdhbL/a2MmZxbm5u7vbnTBmUgMtmDMTilduRsbPaB1OZ7XCa0+Fjb73YWy/2tjJmcXa7D+8tIW+fOwqJ0eG4871Mvq1kNx1uczo87K0Xe+vF3lbGLM5RUVGH9XmxEaG4b95YbC6twUvfbffyVGY73OZ0eNhbL/bWi72tjFmcKysrD/tzTxvbF6eMScI/vsxF4Z46L05ltiNpTt3H3nqxt17sbWXM4pycnHzYnysiuG/eWASL4O4PMmHXiVkCzZE0p+5jb73YWy/2tjJmcd6+/cieku4XF4nb547CirwKfJRR4qWpzHakzal72Fsv9taLva2MOX2n2+1GUNCRfa/R4laY/8xK7Kysw5e3HoeePcK8NJ2ZvNGcuo699WJvvZzQ25Gn70xPTz/ibQQHCf72s/HYW9+M+z/d7IWpzOaN5tR17K0Xe+vF3lbGHDl700Of5+Dp5fl4Y8F0zByWaPc4RERkAEceOXvzjbp/ddJwDOoVhd+9n4mG5havbdc0fHN0vdhbL/bWi72teOR8EN9vrcDPX1iNhScMw22njbR7HCIiCnCOPHJOS0vz6vZmDUvE/MkpePabfGzZtc+r2zaFt5vTobG3XuytF3tbGXPk7ItX+lXub8LJj36DQb2i8O4NMxEUJF7dfqBzwqsr/Ql768Xeejmht9ePnEVkrohsEZGtInLnIW43X0SUiHTpzr0pJyfH69tM6BGGP5w1GhsKq/Ha6h1e336g80VzOjj21ou99WJvq04XZxEJBvAUgNMBjAFwiYiM6eB2MQAWAVjt7SG7IjU11SfbPXdSfxw7PBEPfb4Fu/Y2+OQ+ApWvmlPH2Fsv9taLva26cuQ8DcBWpdQ2pVQTgCUA5nVwuz8DeBCALStYSYlvzuolIvjruePhcrtxz0ebfHIfgcpXzalj7K0Xe+vF3lZdWZz7A9jZ7nKR57ofichkAAOUUp8cakMicr2IrBORdaWlpaioqEBpaSmKi4tRVVWF/Px81NfXIzs7G263+8cXCLS9xD4tLQ1utxvZ2dmor69Hfn4+qqqqUFxcDKUUKioqUFBQgNraWuTk5MDlciEjI8Oyjbb/ZmZmorGxEXl5eaipqUFhYSHKy8tRXl6OwsJC1NTUIC8vD42Njdhbko9bTh6BpVll+HzTrh+3kZGRAZfLhZycHNTW1qKgoMCrj6mtkS8eU2ZmZofb6M5j2rt3r3GPyZ+/TgkJCcY9Jn/+OlVVVRn3mPz56xQSEmLcYzrw69Qdnb4gTETOBzBXKbXAc/lyANOVUgs9l4MAfAXgKqVUgYgsB3CbUuqQr/by9gvCiouL0b9//85veJiaW9w455/fo3J/I7689TjERIT67L4Cha+bkxV768Xeejmht7dfEFYMYEC7yyme69rEABgHYLmIFACYAeAj3S8K8/Wr/EKDg/DAz8ajfF8jHl66xaf3FShMf2Wlv2FvvdhbL/a26kqNtQCGi0iqiIQBuBjAR20fVErtVUolKqUGK6UGA1gF4JzOjpy9LTTU90eyEwfE46qZg/Hqqh1Yv6PK5/fn73Q0p//H3nqxt17sbdXp4qyUcgFYCGApgM0A3lZKZYnIfSJyjq8H7Kra2lot9/ObU0eiX2wEfvXmBmyv2K/lPv2VrubUir31Ym+92NvKmJOQ1NbWIjo62mvbO5TMor248uU1CBJg8dXTMK5/nJb79Tc6mxN768beejmhtyNP31lUVKTtvsanxOHtXxyDsOAgXPL8KqzetkfbffsTnc2JvXVjb73Y28qYI2eXy4WQkBCvba8rSqrrcfmLq1FUVY9/XjoZp4xJ0nr/drOjuZOxt17srZcTejvyyDkrK0v7fSbHR+I/N8zEqL4xuOG19XhnvbO+87OjuZOxt17srRd7Wxlz5Gyn2kYXbnh1Pb7bWoHfnzkaC44dYvdIRETkZxx55GznG3VHh4fgxaum4ozxffGXTzbj4aU5sOubHp345uh6sbde7K0Xe1vxyNmLWtwKf/hwE95YXYhLpg3EX84dh2C+zSQREYFHzrYJDhL89dxxWHjCMLy5phC/enMDWtzmHkH7Q3MnYW+92Fsv9rbikbOPPPdNPv72WQ5+deIw3HrqSLvHISIimznyyLnt3Ub8xfVzhuD8KSl44qut+CqnzO5xfMLfmpuOvfVib73Y28qYxXnEiBF2j2AhIvjLueMwpl8sblmSjsI9dXaP5HX+1tx07K0Xe+vF3lbGLM6FhYV2j/ATEaHBePayKQCAG15bj4bmFpsn8i5/bG4y9taLvfVibytjFuekJP88O9fAXlF47OJJyC6twe8/2GTUr1j5a3NTsbde7K0Xe1sZszhXV1fbPcJBnTgqCb86cRjeWV+EN9fstHscr/Hn5iZib73YWy/2tjJmcY6IiLB7hENadPIIzBnRG/d+lIWMnWbshP7e3DTsrRd768XeVsYszv4uOEjw+EWT0DsmHDe9nobK/U12j0RERH7KmMW5oaHB7hE61bNHGJ65bDJ272vEoiWBf4KSQGhuEvbWi731Ym8rYxbn+Ph4u0fokgkp8fjTvLFYkVeBx77MtXucIxIozU3B3nqxt17sbWXM4lxWFjgn+rj46AG4cGoKnvxqK5ZtDpy5DxRIzU3A3nqxt17sbWXM4jxw4EC7R+gyEcF988ZhbHIsfv1WOrbtrrV7pMMSSM1NwN56sbde7G1lzOKcmxtYTxG3naAkNDgIV7y0BuX7Au/nLYHWPNCxt17srRd7W/GNL2yWsbMaFz+/CkN698BbvzgG0eEhdo9EREQ+4Mg3vgjUtxubOCAeT182GTm79uHG19ajyeW2e6QuC9TmgYq99WJvvdjbikfOfuI/63bit+9sxHlH9cejF06EiNg9EhEReRGPnAPQBVMH4LZTR+D9DcV48PMtdo/TJYHePNCwt17srRd7W/HI2Y8opfD7Dzbh9dWFuPfsMbhqVqrdIxERkZc48sg5IyPD7hGOWNuvWJ06Jgl/+jgbn2aW2j3SIZnQPJCwt17srRd7Wxlz5OxyuRASYsYrnRuaW/DzF1Yjs3gvXr1mGqYP6WX3SB0yqXkgYG+92FsvJ/R25JHz1q1b7R7BayJCg/HCFVMxoGckrvv3OuSW7bN7pA6Z1DwQsLde7K0Xe1sZszinpKTYPYJX9ewRhleumYaI0GBc+dIarN9RCbue5TgY05r7O/bWi731Ym8rYxbniooKu0fwupSeUVh89TTsb3Rh/jM/YPaDX+OBz3KQVbLXLxZqE5v7M/bWi731Ym8rY57gj46OtnsEnxiTHIvv7jwR/8sqw383luCFFdvw7Df5GNK7B86ekIyzJ/bDsD4xtsxmanN/xd56sbde7G1lzOLc3Nxs9wg+ExsRivlTUjB/Sgoq9zfh80278N+MEjzxVR4eX5aHUX1jcPbEZMweloghvXsgJiJUy1wmN/dH7K0Xe+vF3lbGLM5ud+Cc9vJIJPQIw6XTB+LS6QNRXtOATzJL8d+MEjy8dAseXtp68pLeMeEYktgDQ3r3wJDEaAzp3QOpiT0wICEKocHe+0mGU5r7C/bWi731Ym8rYxbnqKgou0fQrk9sBK6elYqrZ6WiuLoem4r3Ytvu/di2uxbbKvZjaVYZKvfv/PH2IUGCE0b1wTM/n4wQLyzSTmxuJ/bWi731Ym8rYxbnyspK9OzZ0+4xbNM/PhL94yN/cn11XRPyd+/H9or9SN9ZhddWFeLl7wtw3ZwhR3yfTm+uG3vrxd56sbeVMYtzcnKy3SP4pfioMEwZFIYpg3pi/uT+2LW3AY/+Lxdzx/XFgIQj+06VzfVib73YWy/2tjLmV6m2b99u9wh+r+30oEEC/O79zCP+dSw214u99WJvvdjbypjFedSoUXaPEBCS4yNx+9xRWJFXgfc3FB/RtthcL/bWi731Ym8rYxbn9PR0u0cIGJfNGITJA+Px54+zsae28bC3w+Z6sbde7K0Xe1sZ88YX1D25Zftw5hMrcNaEZPzjokl2j0NEZDxHvvEF36i7e0YkxeDG44bi/Q3F+CZ392Ftg831Ym+92Fsv9rbikbODNbpacMbjK9DocuOLX89BVJgxL94nIvI7jjxyTktLs3uEgBMeEowH5k9AUVU9Hv0it9ufz+Z6sbde7K0Xe1sZc+TsdrsRFGTM9xpa3f1+Jt5cU4j3b5qFiQPiu/x5bK4Xe+vF3no5obcjj5xzcnLsHiFg3XH6KPSOCced72WiuaXr57dlc73YWy/21ou9rYxZnFNTU+0eIWDFRoTiT+eMw+bSGrywousnAmBzvdhbL/bWi72tjFmcS0pK7B4hoM0d1xdzx/bFY1/moqBif5c+h831Ym+92Fsv9rYyZnFOSEiwe4SA96d5YxEWEoQ739uIRldLp7dnc73YWy/21ou9rYxZnOvq6uweIeAlxUbg92eOxqptlTj98RVYmV9xyNuzuV7srRd768XeVsYszqa/yk+Xi44eiFeumQZXi8Kl/1qNW99KR8VBTvHJ5nqxt17srRd7WxlTIzQ01O4RjHHciN744tdz8MsTh+G/G0tw0t+/wZtrCuF2W3/tjs31Ym+92Fsv9rYyZnGura21ewSjRIQG4zenjsRni+ZgVN8Y3PVeJs5/diU2l9b8eBs214u99WJvvdjbypjFOTEx0e4RjDSsTzSWXD8Df79gIgr21OGsJ7/D/Z9uRl2Ti801Y2+92Fsv9rYyZnEuKiqyewRjiQjmT0nBsluPwwVTUvD8t9twyqPf4tN1eXaP5ijcx/Vib73Y26pLi7OIzBWRLSKyVUTu7ODjN4hIpoiki8h3IjLG+6Me2rBhw3TfpeP07BGGB+ZPwDs3HIPwkCDc9UUpnv82H3adAtZpuI/rxd56sbdVp4uziAQDeArA6QDGALikg8X3DaXUeKXUJAAPAXjU65N2IisrS/ddOtbUwQn4cOEsTOsfgfs/zcFNr6dhX0Oz3WMZj/u4XuytF3tbdeXIeRqArUqpbUqpJgBLAMxrfwOlVE27iz0AaD+Umjhxou67dLSYiFC8cdMJuPuM0fgiuwzz/vk9csv22T2W0biP68XeerG3VVcW5/4Adra7XOS5zkJEbhaRfLQeOf/KO+N1Hd+oW7+0tDRcN2cI3lgwHTUNLsz75/f4ML3Y7rGMxX1cL/bWi72tvPaCMKXUU0qpoQDuAPD7jm4jIteLyDoRWVdaWoqKigqUlpaiuLgYVVVVyM/PR319PbKzs+F2u398f8+2L1paWhrcbjeys7NRX1+P/Px8VFVVobi4GMnJyaioqEBBQQFqa2uRk5MDl8uFjIwMyzba/puZmYnGxkbk5eWhpqYGhYWFKC8vR3l5OQoLC1FTU4O8vDw0NjYiMzOzw21kZGTA5XIhJycHtbW1KCgo8Opjamvkr48pMjISbrcbodU78MmvZmNwXBAWLUnHTS98jYYmV0A+Jn/+Ok2ZMsW4x+TPX6ewsDDjHpM/f52GDBli3GM68OvUHZ2+n7OIHAPgXqXUaZ7LdwGAUupvB7l9EIAqpVTcobbr7fdzbvvHi/Q5sHlzixsPfJaDF7/bjskD4/HUzyejX1ykjROahfu4XuytlxN6d+f9nLuyOIcAyAVwEoBiAGsBXKqUymp3m+FKqTzP388GcE9nA3h7cSb/8fHGEtz+zkZEhgbj+SumYsqgnnaPRERku+4szp0+ra2UcgFYCGApgM0A3lZKZYnIfSJyjudmC0UkS0TSAdwK4MrDnP2wtT1dQfocrPlZE5Lx0cJZ6BEeghtfW489Bzk3N3UP93G92Fsv9rbq9MjZV7x95NzY2Ijw8HCvbY8611nz7JIanPvU95g9PBEvXjkVIqJxOvNwH9eLvfVyQm+vHjkHisLCQrtHcJzOmo9JjsVdZ4zCVznleGVlgZ6hDMZ9XC/21ou9rYxZnJOSkuwewXG60vyqmYNx4qg+uP+zHGSX1HR6ezo47uN6sbde7G1lzOJcXV1t9wiO05XmIoKHz5+AuMhQ/PLNNNQ3tWiYzEzcx/Vib73Y28qYxTkiIsLuERynq817RYfjHxdOwraK/bjv42wfT2Uu7uN6sbde7G1lzOJM/m328ERcP2cI3lxTiM8yS+0eh4jIrxmzODc0NNg9guN0t/lvThmJCSlxuOPdjSiurvfRVObiPq4Xe+vF3lbGLM7x8fF2j+A43W0eFhKEJy4+Ci1uhV8vSUeLm2812R3cx/Vib73Y28qYxbmsrMzuERzncJoPTuyBP587DmsKKvHPr7b6YCpzcR/Xi731Ym8rYxbngQMH2j2C4xxu859NTsG5k5Lx+LJcrC2o9PJU5uI+rhd768XeVsYszrm5uXaP4DhH0vzP545DSs8o3LIkHXvrmr04lbm4j+vF3nqxt5Uxp++kwJO+sxrnP7MSp45NwlOXTubpPYnIaI48fSffqFu/I20+aUA8fnPqSHyauQtvrd3ppanMxX1cL/bWi72teORMtnK7Fa54aQ3W7ajEfxfOxvCkGLtHIiLyCR45kxbeaB4UJHj0wonoERaCX765AQ3NPL3nwXAf14u99WJvKx45k1/4OqccVy9eiyuPGYQ/zRtn9zhERF7nyCPnjIwMu0dwHG82P2FUH1w7OxWv/LAD/8vm7zt2hPu4XuytF3tbGXPk7HK5EBIS4rXtUee83bzR1YKfPb0SxdX1+HzRHPSN44nw2+M+rhd76+WE3o48ct66lWeb0s3bzcNDgvHkJUehyeXGoiUbeHrPA3Af14u99WJvK2MW55SUFLtHcBxfNB/SOxr3zRuH1dsr8fTX/J+1Pe7jerG3XuxtZcziXFFRYfcIjuOr5vMn98e8Scl4bFke1vH0nj/iPq4Xe+vF3lbGLM7R0dF2j+A4vmoPd8JeAAAgAElEQVQuIvjLueOQHB+BRUvSsbeep/cEuI/rxt56sbeVMYtzczP/AdfNl81jIkLx5CWTUVbTgN+9lwm7XrjoT7iP68XeerG3lTGLs9vttnsEx/F180kD4nHbaSPxSWYplvD0ntzHNWNvvdjbypjFOSoqyu4RHEdH8+uPHYLZwxJxz0dZWLbZ2b//zH1cL/bWi72tjFmcKyv5wiHddDQPChI8eclRGNU3Br94dT0+TC/2+X36K+7jerG3XuxtZczinJycbPcIjqOrec8eYXh9wXRMHdwTt7yVjld/KNByv/6G+7he7K0Xe1sZszhv377d7hEcR2fzmIhQLL56Gk4alYQ/fJiFJ5flOe5FYtzH9WJvvdjbypjTd7rdbgQFGfO9RkCwo7mrxY3b39mI9zYUY8HsVNx95miIiNYZ7MJ9XC/21ssJvR15+s709HS7R3AcO5qHBAfhkQsm4qqZg/HCd9tx+zsb4Wpxxqs8uY/rxd56sbeVMUfO5CxKKTy+LA+PfZmHuWP74vFLJiE8JNjusYiIDsqRR858o2797GwuIrjl5BH441lj8HnWLly7eB32N7psm0cH7uN6sbde7G3FI2cKeO+uL8Lt727E+P5xWHz10YiPCrN7JCKin3DkkXNaWprdIziOvzSfPyUFT/98MrJLa3DRc6tQXtNg90g+4S+9nYK99WJvK2OOnJ3wSj9/42/NV26twHX/Xode0eF47drpGNjLrDMO+Vtv07G3Xk7o7cgj55ycHLtHcBx/az5zWCJev24Gahqacf6zK7Fl1z67R/Iqf+ttOvbWi72tjFmcU1NT7R7Bcfyx+aQB8fjPL46BCHDhcz8grbDK7pG8xh97m4y99WJvK2MW55KSErtHcBx/bT48KQbv3DAT8VGhuOyF1fguz4w3cffX3qZib73Y28qYxTkhIcHuERzHn5sPSIjCf244BgMTonDN4rX4fFOp3SMdMX/ubSL21ou9rYxZnOvq6uwewXH8vXmfmAi8df0xGJ8Sh5teT8PbAf6e0P7e2zTsrRd7WxmzOJv+Kj9/FAjN46JC8eq10zB7eG/c/u5GvLBim90jHbZA6G0S9taLva2MqREaGmr3CI4TKM2jwkLwwhVTceb4fvjLJ5tx238yUF3XZPdY3RYovU3B3nqxt5Uxi3Ntba3dIzhOIDUPCwnCE5cchZtPGIr3NxTjpL9/gw/TiwPqbScDqbcJ2Fsv9rYyZnFOTEy0ewTHCbTmwUGC3542Cv9dOBspCVFYtCQdV768FjsrA+NnXYHWO9Cxt17sbWXM4lxUVGT3CI4TqM3HJMfivRtn4t6zx2B9QSVO+cc3eP7bfL9/68lA7R2o2Fsv9rYy5vSdLpcLISEhXtsedc6E5iXV9fjjh1n4cnMZxvSLxQPzx2NCSrzdY3XIhN6BhL31ckJvR56+Mysry+4RHMeE5snxkfjXFVPw7GWTUVHbiHOf+h73/TcbtX749pMm9A4k7K0Xe1sZc+RMdKRqGprx0Oc5eG1VIeIiQ3HxtAG44pjB6B8fafdoRGQARx4584269TOteWxEKP5y7nh8cPMszBzaC//6dhuOffAr3PjaeqzZXmn7K7tN6+3v2Fsv9rbikTPRQRRV1eHVVTuwZM1O7K1vxtjkWFw9KxVnT+yH8JBgu8cjogDDI2fSwvTmKT2jcNfpo/HDXSfir+eNQ5PLjdv+k4FZD3yFR/+Xi117G7TOY3pvf8PeerG3FY+cibpIKYXvtlZg8fcF+GpLOZQCRvWNwexhiZg9PBHTUhMQFWb2q02J6PB158jZmMU5MzMT48eP99r2qHNObl5QsR+fbirF91srsLagCk0uN8KCgzB5ULxnse6N8f3jEBwkXrtPJ/e2A3vr5YTejlycGxsbER4e7rXtUefYvFV9UwvWFlTi+60VWJFXgezSGgBAbEQIpqUmoF9cJHpFhyExOhyJ0eHoHfP/f48KC4ZI1xZw9taLvfVyQu/uLM7GPAdXWFiI4cOH2z2Go7B5q8iwYMwZ0RtzRvTGXQD21Dbi+/w9+C5vNzYUVmPdjipU1zV3+LkRoUHoFxeJO+aOxNxx/Q55P+ytF3vrxd5Wxhw519TUIDY21mvbo86xedc1udyo3N+EitpGzx/P3/c1YmX+HmzeVYN7zx6LK2cOPug22Fsv9tbLCb29fuQsInMBPA4gGMALSqkHDvj4rQAWAHAB2A3gGqXUjm5NfYSqq6uN/8L6GzbvurCQIPSNi0DfuIiffKy+qQW/fHMD7vkoC2U1DfjtaSM7fKqbvfVib73Y26rTX6USkWAATwE4HcAYAJeIyJgDbrYBwFSl1AQA7wB4yNuDdiYi4qf/6JFvsbl3RIYF49nLJuOSaQPx9PJ8/OY/GWju4E042Fsv9taLva268nvO0wBsVUptU0o1AVgCYF77GyilvlZKtb3v3ioAKd4dk8hsIcFBuP+8cbj1lBF4L60Y176yzi/P701EenRlce4PYGe7y0We6w7mWgCfdfQBEbleRNaJyLrS0lJUVFSgtLQUxcXFqKqqQn5+Purr65GdnQ232420tDQA///L6WlpaXC73cjOzkZ9fT3y8/NRVVWF4uJilJWVoaKiAgUFBaitrUVOTg5cLhcyMjIs22j7b2ZmJhobG5GXl4eamhoUFhaivLwc5eXlKCwsRE1NDfLy8tDY2IjMzMwOt5GRkQGXy4WcnBzU1taioKDAq4+prZG/PqZt27YZ95js/Drt3r0b5w4Px71nDMd3ebtx0XMr8e2a9B8/t6GhIeAeUyB/nbZu3WrcY/Lnr9OePXuMe0wHfp26o9MXhInI+QDmKqUWeC5fDmC6UmphB7e9DMBCAMcppRoPtV2+ICzwsbnvfJVThpteT0OfmAj8+5ppGJzYg701Y2+9nNDb26fvLAYwoN3lFM91B97pyQDuBnBOZwuzL5SVlem+S8djc985cVQS3rxuBmobXZj/zEqk76xmb83YWy/2turK4rwWwHARSRWRMAAXA/io/Q1E5CgAz6F1YS73/pidGzhwoB1362hs7ltHDeyJd244BlHhwbjk+VUodkXbPZKjcP/Wi72tOl2clVIutD5VvRTAZgBvK6WyROQ+ETnHc7OHAUQD+I+IpIvIRwfZnM/k5ubqvkvHY3PfG9I7Gu/eOBMDEiKxaEk6yvfpfbMNJ+P+rRd7WxlzEhIik+WV7cNZT36HGUN64eWrjkaQF8/ZTUR68C0jSQs212d4UgyumBCNb3J3Y/HKArvHcQTu33qxtxWPnIkChFIK1/17Hb7NrcCHC2dhdD+zX9lKZBoeOZMWbK5XWloaHpw/AXFRoVi0ZAMamlvsHslo3L/1Ym8rHjkTBZhvcnfjypfW4MpjBuFP88bZPQ4RdZEjj5zbzh5D+rC5Xm29jxvRG9fMSsUrP+zA1zm2/OaiI3D/1ou9rYw5cna5XAgJMebtqQMCm+vVvndDcwvOfep7VNQ24rNFc9A7xuw3qbcD92+9nNDbkUfOW7dutXsEx2Fzvdr3jggNxhOXHIV9DS789p0M2PVNtsm4f+vF3lbGLM4pKXwjLN3YXK8De49IisHdZ47G8i389Spf4P6tF3tbGbM4d/cdP+jIsbleHfW+fMYgnDSqD/72WQ5ydtXYMJW5uH/rxd5WxizO0dE877BubK5XR71FBA+ePwGxEaFY9GY6f73Ki7h/68XeVsYszs3NzXaP4DhsrtfBeidGh+ORCyZgS9k+/PWTzZqnMhf3b73Y28qYxdntdts9guOwuV6H6n38yD647thUvLpqB15btUPjVObi/q0Xe1sZ87r1qKgou0dwHDbXq7Ped54+Gvm79+Oej7IwMCEKc0b01jSZmbh/68XeVsYcOVdWVto9guOwuV6d9Q4OEjxxyVEY3icaN7+ehtyyfZomMxP3b73Y28qYxTk5OdnuERyHzfXqSu/o8BC8dNXRiAgLxtUvr8XufY0aJjMT92+92NvKmMV5+/btdo/gOGyuV1d7J8dH4sUrp2LP/kZc/+o6voL7MHH/1ou9rYw5fafb7UZQkDHfawQENteru70/31SKG15Lw1kT+uGJi49CUJD4cDrzcP/Wywm9HXn6zvT0dLtHcBw216u7veeO64c7Tx+FjzeW4rEvc300lbm4f+vF3lbGHDkT0U8ppXDnu5l4a91O/P2CiZg/hadIJLKLI4+c+Ubd+rG5XofTW0Tw53PHYebQXrjzvY1YvW2PDyYzE/dvvdjbikfORA6wt64Z5z3zPSr3N+GDm2ZhcGIPu0cichxHHjmnpaXZPYLjsLleR9I7LioUL191NATA1YvXorymwXuDGYr7t17sbWXMkbMTXunnb9hcL2/0Xr+jEpe/uAZJsRF447rp6BcX6aXpzMP9Wy8n9HbkkXNOTo7dIzgOm+vljd5TBiXg1WunYfe+Rlz03CoUVdV5YTIzcf/Wi72tjFmcU1NT7R7BcdhcL2/1njIoAa8tmI7quiZc9NwqFO7hAt0R7t96sbeVMYtzSUmJ3SM4Dpvr5c3ekwbE443rZmB/kwsXPf8Dtlfs99q2TcH9Wy/2tjJmcU5ISLB7BMdhc7283Xtc/zi8ed0MNLrcuOi5H7C1nG+U0R73b73Y28qYxbmujk/N6cbmevmi9+h+sVhy/Qy4FXDx86uwZRcX6Dbcv/VibytjFmfTX+Xnj9hcL1/1HpEUg7d+MQPBQYKLn/8BWSV7fXI/gYb7t17sbWVMjdDQULtHcBw218uXvYf2jsZb1x+DyNBgXPqv1dhYVO2z+woU3L/1Ym8rYxbn2tpau0dwHDbXy9e9Byf2wFu/OAYxESH4+b9WY0Xebp/en7/j/q0Xe1sZszgnJibaPYLjsLleOnoPSIjC2784BsnxkbjypTV47pt82HWiIrtx/9aLva2MWZyLiorsHsFx2FwvXb2T4yPx3k0zcfr4fvjbZzlY+OYG1DW5tNy3P+H+rRd7Wxlz+k6Xy4WQkBCvbY86x+Z66e6tlMJz327DQ5/nYERSDJ67fAoG9XLOG2Zw/9bLCb0defrOrKwsu0dwHDbXS3dvEcENxw3F4qunoXRvA85+8jss31KudQY7cf/Wi72tjDlyJiLfKdxTh+tfXYctZftw26kjcdPxQyEido9FFFAceeTMN+rWj831srP3wF5ReO+mmTh7QjIeXroFN72ehtpGs38Ozf1bL/a24pEzEXWZUgovfrcd93+6GUN7R+Opn0/GiKQYu8ciCgg8ciYt2Fwvf+gtIlhw7BC8du107NnfhDOfWIFHlm5BQ3OL3aN5nT/0dhL2tuKRMxEdlj21jfjrp5vxXloxBvWKwl/PHY/Zw/m7qkQH48gj58zMTLtHcBw218vfeveKDsejF07CGwumI0gEl724Grcs2YCK2ka7R/MKf+ttOva2MubIubGxEeHh4V7bHnWOzfXy594NzS14+uuteOabfESFheCu00fhwqkDEBQUuK/o9ufeJnJCb0ceORcWFto9guOwuV7+3DsiNBi3njoSny06FiOTYnDne5m4+PlVyCsL3Leg9OfeJmJvK2MW56SkJLtHcBw21ysQeg/rE4Ml18/AQ/MnYEvZPpzxxAr85eNslNc02D1atwVCb5Owt5Uxi3N1Nd/iTjc21ytQegcFCS48egCW/eY4zJvUHy99vx2zH/wav3s/E4V76uwer8sCpbcp2NvKmMU5IiLC7hEch831CrTeidHheOSCifj6tuNx/tQUvLOuCMc/8jUWLdmAnF01do/XqUDrHejY28qYxZmI/NOgXj1w/3njseKOE7Dg2CH4MrsMcx9bgQWvrMX6HVV2j0fkl4xZnBsaAu9nWoGOzfUK9N5JsRH43Rmj8f2dJ+LWU0Zg/Y4qzH9mJS5+/gcs21yGJpfb7hEtAr13oGFvK2N+laqmpgaxsbFe2x51js31Mq13XZMLb67ZiX99uw27ahoQFxmKU8Yk4YzxfTF7WG+Ehdh77GBab3/nhN7d+VUqY948s6yszPgvrL9hc71M6x0VFoJrZ6fi8hmD8G3ubny6qRRLs3bhnfVFiIkIwSmjk3DG+H6YPTwREaHB2uczrbe/Y28rY46cnfAL7P6GzfVyQu9GVwtWbt2DTzJL8UXWLtQ0uBAdHoKTRvfB3LF9MWlgPPrGRmh5u0on9PYnTujtyCPn3NxcjB8/3u4xHIXN9XJC7/CQYJwwqg9OGNUHTeeNx8r8CnyWuQtLs3fhw/QSAEBCjzCMTY7FmORYjEuOw9jkWAzu1cPrZyNzQm9/wt5Wxhw5E5G5mlvc2FhUjaySGmwq3ouskhrklu1Dc0vrv189woIxul/rgp0UG4G4yFDERYYiPsrz38gwxEWGIiYiJKBPKUqBzZFHzuvXr8eUKVPsHsNR2FwvJ/cODQ7ClEEJmDIo4cfrmlxu5JXvQ1ZxDbJKWhfs99KKUdvoOuh2RIC4yFCcPq4v7jpjNGIjQg96Wyf3tgN7W3XpyFlE5gJ4HEAwgBeUUg8c8PE5AB4DMAHAxUqpdzrbJo+cicgXGppbUFPfjL31zaiub0Z1nefvdU3YW9+M4qp6fJBejKTYCNz/s/E4YWQfu0cmh/DqG1+ISDCApwCcDmAMgEtEZMwBNysEcBWAN7o3qvfwjbr1Y3O92LtrIkKD0Sc2AsOTYnD04AScMiYJ509JwYJjh+A3p47EoxdNwns3zUJ0eAiufnktfvufDOytb/7JdthbL/a26vTIWUSOAXCvUuo0z+W7AEAp9bcObrsYwMc8ciYif9foasGTy1rf5jIxOgz3nzceJ43mmy+Q73j7LSP7A9jZ7nKR5zq/kpGRYfcIjsPmerG3d4WHBOO200big5tmIT4yDNe+sg63vpWO6romAOytG3tbaT0Fj4hcLyLrRGRdaWkpKioqUFpaiuLiYlRVVSE/Px/19fXIzs6G2+1GWloagP9/uiMtLQ1utxvZ2dmor69Hfn4+qqqqUFxcjMTERFRUVKCgoAC1tbXIycmBy+X68Qveto22/2ZmZqKxsRF5eXmoqalBYWEhysvLUV5ejsLCQtTU1CAvLw+NjY3IzMzscBsZGRlwuVzIyclBbW0tCgoKvPqY2hr562MKDg427jH589dp7Nixxj0mf/g6ufcU4L+/nI3zR/fARxklOP6hZfhfdhlEJGAfUyB+nfr372/cYzrw69QdxjytnZOTg1GjRnlte9Q5NteLvX1vU/Fe/PadjdhcWoO5w2Pw1NXHIpi/eqWFE/Zvbz+tvRbAcBFJFZEwABcD+OhIBvSFlJQUu0dwHDbXi719b1z/OHx48yzcePxQfJ63D3e8uxFutz3ngnAa7t9WnS7OSikXgIUAlgLYDOBtpVSWiNwnIucAgIgcLSJFAC4A8JyIZPly6I509ykDOnJsrhd76xEWEoQ75o7C1VN74531Rbj7g0wu0Bpw/7bq0klIlFKfAvj0gOv+2O7vawHY+m1PdHS0nXfvSGyuF3vrddNxqYiKicVTX+cjNDgIfzpnrJZzejsV928rY84Q1tz8099TJN9ic73YWy+Xy4XbTh2J5haF57/dhpCgIPzhrNFcoH2E+7eVMYuz2+1fb9TuBGyuF3vr5Xa7ISK46/RRaHK58dL32xEaIrhz7igu0D7A/dvKmMU5KirK7hEch831Ym+92nqLCO45ewxcbjee+2YbwoODcOupI22ezjzcv620/p6zL1VWVto9guOwuV7srVf73iKC+84Zh4umDsATX23FE8vybJzMTNy/rYw5ck5OTrZ7BMdhc73YW68DewcFCf72s/FobnHj0f/lIjQ4CDceP9Sm6czD/dvKmCPn7du32z2C47C5XuytV0e9g4IED18wEWdPTMaDn+fghRXbbJjMTNy/rbr0lpG+4O0zhLndbgQFGfO9RkBgc73YW69D9Xa1uPHLNzfgs0278Is5Q3DH3FEI4pnEjogT9m9vnyEsIKSnp9s9guOwuV7srdeheocEB+HJS47CZTMG4rlvt+HG19ejrsmlcTrzcP+2MubImYhIN6UUXv6+AH/+JBvjkuPwwpVTkRQbYfdY5KcceeTMN+rWj831Ym+9utJbRHDN7FS8cMVU5O+uxbx/fo+skr0apjMP928rHjkTEXlBdkkNrn1lLfbWN+OJi4/CyWOS7B6J/Iwjj5zb3luT9GFzvdhbr+72HpMciw9vnoVhfaJx3avr8MKKbbDr4CcQcf+2MubI2Qmv9PM3bK4Xe+t1uL3rm1rw67fS8XnWLlw6fSD+dM5YhAbz69YZJ+zfjjxyzsnJsXsEx2Fzvdhbr8PtHRkWjKd/Phk3Hj8Ub6wuxDWL16Jyf5OXpzMP928rYxbn1NRUu0dwHDbXi731OpLeQUGCO+aOwkPnT8CqbXtw2mPfYvmWci9OZx7u31bGLM4lJSV2j+A4bK4Xe+vljd4XTh2AD2+ejYSoMFz18lr84YNN/H3og+D+bWXM4pyQkGD3CI7D5nqxt17e6j0mORYfLpyF645NxWurd+CsJ75D+s5qr2zbJNy/rYxZnOvq6uwewXHYXC/21subvSNCg3H3mWPw+oLpaGhuwfxnVuKxL3PR3ML3MG7D/dvKmMXZ9Ff5+SM214u99fJF75lDE/HZLXMwb2IyHvsyD+c/+wO27a71+v0EIu7fVsbUCA0NtXsEx2FzvdhbL1/1josMxaMXTcJTl07Gjj37ccYTK/Dqqh2O/51o7t9WxizOtbX87lM3NteLvfXyde8zJ/TD0lvm4OjBCfjDB5twwbM/OPpn0dy/rYxZnBMTE+0ewXHYXC/21ktH76TYCPz7mml4cP54FOypw7lPfY9FSzagqMp5P3/l/m1lzOJcVFRk9wiOw+Z6sbdeunqLCC46eiCW//Z4/PLEYfh80y6c+Pdv8ODnOdjX0KxlBn/A/dvKmNN3ulwuhISEeG171Dk214u99bKrd0l1PR5ZugXvbShGrx5huPXUEbho6gCEGH4KUCfs3448fWdWVpbdIzgOm+vF3nrZ1Ts5PhKPXjQJHy2chaF9onH3+5tw+uMrjD/DGPdvK2OOnImITKOUwtKsMjzw2WYU7KnDtNQELJidipNGJyE4SOwej7rJkUfOfKNu/dhcL/bWyx96iwjmjuuLL359HO45ewyKq+px/avrceLfl+Pl77ejttGcU4H6Q29/wiNnIqIA4Wpx44vsMrz43Xas31GFmPAQXHT0AFw5czAGJETZPR51gkfOpAWb68Xeevlj75DgIJwxvh/evXEmPrh5Fk4Y1QeLVxbguIe/xo2vrcfagsqAPZmJP/a2E4+ciYgCWOneeryycgfeXFOIvfXNGN0vFmdP7IczxvXD4MQedo9H7TjyyDkzM9PuERyHzfVib70CpXe/uEjcefoo/HDXifjzueMQHhKEhz7fguMfWY4zHl+Bp77eiu0V++0es1OB0lsXY46cGxsbER4e7rXtUefYXC/21iuQexdX1+OzzFJ8mlmKtMLWU4KO6huDM8f3wxkT+mFo72ibJ/ypQO7dVd05cjZmcc7Ly8Pw4cO9tj3qHJvrxd56mdK7pLoen23ahc8yS7FuRxUAYERSNKan9sLUwT0xZVBP9I+PhIi9v5plSu9DceTiXFNTg9jYWK9tjzrH5nqxt14m9t61twGfbSrFss3l2FBYhf1NLQCAvrERmDKodaGeOrgnxvSL1X5GMhN7H6g7i7Mx50qrrq42/gvrb9hcL/bWy8TefeMicPWsVFw9KxWuFjdydu3D+h1VP/75JLMUABAZGoyJA+IwvE8MBvWKwoCEKAzqFYWBCVGICvPNsmFi7yNhzOIcERFh9wiOw+Z6sbdepvcOCQ7CuP5xGNc/DlfOHAyg9ZXf6wpaF+oNhVX4ML0YNQ3WE530jgnHwIQoDEqIwsBeUejVIwyRYSHoERaMyLBg9AgPQWRoMKLa/h4WjOiwEAR1ckYz03t3lzGLMxERHZl+cZE4e2Ikzp6Y/ON11XVN2LGnDoWVrX927NmPHXvq8MO2PXg/vRhd+clov7gIXD1rMC6ZNhAxEaE+fATmMGZxbmhosHsEx2FzvdhbL/ZuFR8VhvioMEwcEP+TjzW6WlBT70J9Uwv2N7lQ19Ty499/vK6xBV/llOP+T3Pw5LKtuGT6QFw9azD6xUVatsXeVsYszvHxP91xyLfYXC/21ou9OxceEozeMcGd3u66OUOwsaga/1qxHS9+tx0vfbcd50xMxoJjh2BMcuvPmdnbypiTkJSVldk9guOwuV7srRd7e9eElHg8eclRWH7b8bj8mEH4PGsXznhiBS5/cTVW5O3Grl277B7Rrxjzq1RO+AV2f8PmerG3XuztW9V1TXh9dSEWryzA7n2NGJscg0cumITR/cx9xbYjT9+Zm5tr9wiOw+Z6sbde7O1b8VFhuPmEYfjujhPw4PzxKKncj3n//B7PfZOPFndgvnmHNxlz5ExERIGrcn8T7npvI5ZmlWFaagIevXAiUnqa9TaYjjxy5tuN6cfmerG3Xuyt1/acTDx72RQ8fP4EZJfU4PTHVuDd9UUB+xaYR4pHzkRE5Fd2Vtbh1rfTsbagCqeP64u/njceCT3C7B7riPHImbRgc73YWy/21qt97wEJUVhy/TG4Y+4ofLm5DKc99i2Wbym3cTr9eORMRER+K6tkL379Vjpyy2px+YxBuH3uyIA9y5gjj5wzMjLsHsFx2Fwv9taLvfU6WO+xyXH4aOFsLJidildX7cAJj3yDt9YWGv+KbmOOnF0uF0JCjDnhWUBgc73YWy/21qsrvdN3VuO+/2YhrbAaY5Nj8cezxmD6kF6aJjxyjjxy3rp1q90jOA6b68XeerG3Xl3pPWlAPN69cSYev3gSKvc34aLnV+Gm19djZ2Wdhgn1MubIuba2FtHR0V7bHnWOzfVib73YW6/u9q5vasHz327DM99shVsBC2an4qYThiE63H+f7XDkkXNFRYXdIzgOm+vF3gpfkKcAAAgISURBVHqxt17d7R0ZFoxFJw/H17cdjzPG9cXTy/NxwiPL8fa6nXAb8PNoYxZnfoerH5vrxd56sbdeh9u7X1wkHrv4KLx300z0j4/E7e9sxMn/+AZvr92JRleLl6fUx5jFubm52e4RHIfN9WJvvdhbryPtPXlgT7x340z889KjEBESjNvf3Yg5D32N57/Nx76GwPtaGrM4u91uu0dwHDbXi731Ym+9vNE7KEhw1oRkfPKr2XjlmmkYkhiN+z/NwcwHvsLDS3Owe1+jFybVo0uLs4jMFZEtIrJVRO7s4OPhIvKW5+OrRWSwtwftTFSUWSdIDwRsrhd768Xeenmzt4jguBG98eb1M/DhzbMwe1ginl6ej1kPfoXff5CJwj3+/+ruTl/WJiLBAJ4CcAqAIgBrReQjpVR2u5tdC6BKKTVMRC4G8CCAi3wx8MFUVlaiZ8+eOu/S8dhcL/bWi7318lXviQPi8cxlU7Btdy3+tWIb3l5bhDdWF2LigHgkx0ciOS4CyfGR6BcXieT4CPSLi0RidBhExOuzdEenv0olIscAuFcpdZrn8l0AoJT6W7vbLPXc5gcRCQGwC0BvdYiNe/tXqerr6xEZGem17VHn2Fwv9taLvfXS1bu8pgGLVxYgfWc1Svc2oKS6Ho0u61PqYSFB6BcXgYEJUfj3NdO8tlB7+1ep+gPY2e5ykee6Dm+jlHIB2AvgJ6dtEZHrRWSdiKwrLS1FRUUFSktLUVxcjKqqKuTn56O+vh7Z2dlwu91IS0sD8P8nRE9LS4Pb7UZ2djbq6+uRn5+PqqoqFBcXIzMzExUVFSgoKEBtbS1ycnLgcrl+PCVc2zba/puZmYnGxkbk5eWhpqYGhYWFKC8vR3l5OQoLC1FTU4O8vDw0NjYiMzOzw21kZGTA5XIhJycHtbW1KCgo8Opjamvkr49p7dq1xj0mf/46bd++3bjH5M9fpzVr1hj3mPz567R582Ytj6lPbARO6r0fb1w3A4+cEIOcP8/Fv8/rhw9uOgb3nNgXvzttGH42tidG9o5EsNuFkpISr32duqMrR87nA5irlFrguXw5gOlKqYXtbrPJc5siz+V8z20OOo23j5zdbjeCgox5fVtAYHO92Fsv9tbLCb29feRcDGBAu8spnus6vI3nae04AHu6MoC3pKen67w7Apvrxt56sbde7G3VlSPnEAC5AE5C6yK8FsClSqmsdre5GcB4pdQNnheE/UwpdeGhtsu3jCQiIifx6pGz52fICwEsBbAZwNtKqSwRuU9EzvHc7EUAvURkK4BbAfzk1618jW+Mrh+b68XeerG3XuxtZcwbXxAREfkzR77xRdsr50gfNteLvfVib73Y28qYI2cnvNLP37C5XuytF3vr5YTejjxyzsnJsXsEx2FzvdhbL/bWi72tjFmcU1NT7R7BcdhcL/bWi731Ym8rYxbnkpISu0dwHDbXi731Ym+92NvKmMU5ISHB7hEch831Ym+92Fsv9rYyZnGuq/P/twAzDZvrxd56sbde7G1lzOJs+qv8/BGb68XeerG3XuxtZUyN0NBQu0dwHDbXi731Ym+92NvKtt9zFpHdAHZ4cZOJALr3nlx0pNhcL/bWi731ckLvQUqp3l25oW2Ls7eJyLqu/nI3eQeb68XeerG3XuxtZczT2kRERKbg4kxERORnTFqcn7d7AAdic73YWy/21ou92zHmZ85ERESmMOnImYiIyAhGLM4iMldEtojIVhG50+55TCMiL4lIuYhsanddgoj8T0TyPP/taeeMJhGRASLytYhki0iWiCzyXM/mPiIiESKyRkQyPM3/5Lk+VURWe/5teUtEwuye1RQiEiwiG0TkY89ltm4n4BdnEQkG8BSA0wGMAXCJiIyxdyrjLAYw94Dr7gSwTCk1HMAyz2XyDheA3yilxgCYAeBmzz7N5r7TCOBEpdREAJMAzBWRGQAeBPAPpdQwAFUArrVxRtMsArC53WW2bifgF2cA0wBsVUptU0o1AVgCYJ7NMxlFKfUtgMoDrp4H4BXP318BcK7WoQymlCpVSqV5/r4Prf+A9Qeb+4xqVeu5GOr5owCcCOAdz/Vs7iUikgLgTAAveC4L2NrChMW5P4Cd7S4Xea4j30pSSpV6/r4LQJKdw5hKRAYDOArAarC5T3meZk0HUA7gfwDyAVQrpVyem/DfFu95DMDtANyey73A1hYmLM5kM9X6kn++7N/LRCQawLsAblFK1bT/GJt7n1KqRSk1CUAKWp+RG2XzSEYSkbMAlCul1ts9iz8LsXsALygGMKDd5RTPdeRbZSLSTylVKiL90Hq0QV4iIqFoXZhfV0q957mazTVQSlWLyNcAjgEQLyIhniM6/tviHbMAnCMiZwCIABAL4HGwtYUJR85rAQz3vNIvDMDFAD6yeSYn+AjAlZ6/XwngQxtnMYrn528vAtislHq03YfY3EdEpLeIxHv+HgngFLT+rP9rAOd7bsbmXqCUuksplaKUGozWf6+/Ukr9HGxtYcRJSDzfgT0GIBjAS0qpv9o8klFE5E0Ax6P1XWPKANwD4AMAbwMYiNZ3F7tQKXXgi8boMIjIbAArAGTi/38m9zu0/tyZzX1ARCag9UVIwWg9aHlbKXWfiAxB64tMEwBsAHCZUqrRvknNIiLHA7hNKXUWW1sZsTgTERGZxISntYmIiIzCxZmIiMjPcHEmIiLyM1yciYiI/AwXZyIiIj/DxZmIiMjPcHEmIiLyM1yciYiI/Mz/AdCiFkAt7kQHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(min_elem)\n",
    "plt.title(\"Min element of mask\", fontsize=14)\n",
    "plt.grid(ls=\":\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4678,\n",
       " 0.4394,\n",
       " 0.41,\n",
       " 0.3934,\n",
       " 0.38,\n",
       " 0.3613,\n",
       " 0.35,\n",
       " 0.34,\n",
       " 0.3378,\n",
       " 0.32,\n",
       " 0.31,\n",
       " 0.2947,\n",
       " 0.27,\n",
       " 0.2546,\n",
       " 0.23,\n",
       " 0.2275,\n",
       " 0.2183,\n",
       " 0.212,\n",
       " 0.2081,\n",
       " 0.2068,\n",
       " 0.1938,\n",
       " 0.1734,\n",
       " 0.1563,\n",
       " 0.1421,\n",
       " 0.1305,\n",
       " 0.1214,\n",
       " 0.1145,\n",
       " 0.1097,\n",
       " 0.1069,\n",
       " 0.1059,\n",
       " 0.09624987095594406,\n",
       " 0.08134373277425766,\n",
       " 0.06899028271436691,\n",
       " 0.05886765569448471,\n",
       " 0.050713829696178436,\n",
       " 0.04431476444005966,\n",
       " 0.03950249403715134,\n",
       " 0.036153219640254974,\n",
       " 0.03418009728193283,\n",
       " 0.03352943807840347,\n",
       " 0.02690904587507248,\n",
       " 0.016768820583820343,\n",
       " 0.008439145982265472,\n",
       " 0.0016614049673080444,\n",
       " 0.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   12\n",
      "Num steps:    56120\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c293fea47cc24ea0ae3cc3776c4eea8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 43634561834.00535, 'train_global_step': 11226}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2947, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8950227023856846, 'eval_accuracy': 0.8681192660550459, 'eval_f1_score': 0.8815653964984552, 'eval_matthews_corrcoef': 0.7490285297671831}\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530415859d1e45dc8c8e6a8d1f546842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 41574228103.00089, 'train_global_step': 22452}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2546, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.6675180818107971, 'eval_accuracy': 0.9059633027522935, 'eval_f1_score': 0.9100877192982456, 'eval_matthews_corrcoef': 0.8129088273674456}\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea0d253e42846c8bae716b520ce6538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 39977772242.71085, 'train_global_step': 33678}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2275, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8225862858146175, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9086809470124014, 'eval_matthews_corrcoef': 0.8141675815843189}\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fb663e7e464f0e9c9a4f1b89b0f975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 39380932260.28149, 'train_global_step': 39291}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2183, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7950202624074657, 'eval_accuracy': 0.9048165137614679, 'eval_f1_score': 0.9074693422519509, 'eval_matthews_corrcoef': 0.8096695019638379}\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec85a0b70e1492ebbbcfbd8eacb2d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 38623734366.04454, 'train_global_step': 50517}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2081, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9122233610882495, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9100998890122087, 'eval_matthews_corrcoef': 0.814418593292671}\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0e948ae6c44876a14a137dff0d18e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 38471000427.40781, 'train_global_step': 56130}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.2068, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9783678258170956, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9110867178924259, 'eval_matthews_corrcoef': 0.8151154105091728}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'file_to_save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bd0221c0d130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                       \u001b[0mvalid_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                       checkpoint_files=checkpoint_files)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b24856c28821>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, params, train_examples, valid_examples, checkpoint_files)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     output_model_file = os.path.join(params['output_dir'],\n\u001b[0;32m--> 112\u001b[0;31m                                      checkpoint_files['file_to_save'])\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     output_config_file = os.path.join(params['output_dir'],\n",
      "\u001b[0;31mKeyError\u001b[0m: 'file_to_save'"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 10\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.4678, 0.4394, 0.3934, 0.3613, 0.3378,\n",
    "0.2947, 0.2546, 0.2275, 0.2183, 0.2081,\n",
    "0.2068,\n",
    "0.1938, 0.1734, 0.1563, 0.1421, 0.1305, 0.1214, 0.1145, 0.1097, 0.1069, 0.1059\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.4004475919954605, 'eval_accuracy': 0.8497706422018348, 'eval_f1_score': 0.8693918245264207, 'eval_matthews_corrcoef': 0.7238845846466488}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.24314538201986646, 'eval_accuracy': 0.9036697247706422, 'eval_f1_score': 0.9096774193548388, 'eval_matthews_corrcoef': 0.810719464505683}\n",
    "    \n",
    "min: tensor( device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.3890809525065773, 'eval_accuracy': 0.908256880733945, 'eval_f1_score': 0.9120879120879121, 'eval_matthews_corrcoef': 0.8173256013364172}    \n",
    "\n",
    "min: tensor( device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.559089559189145, 'eval_accuracy': 0.9105504587155964, 'eval_f1_score': 0.9142857142857143, 'eval_matthews_corrcoef': 0.8219244290540338}\n",
    "    \n",
    "min: tensor( device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.6458157275523319, 'eval_accuracy': 0.9197247706422018, 'eval_f1_score': 0.9229074889867842, 'eval_matthews_corrcoef': 0.840146605877374}    \n",
    "\n",
    "min: tensor( device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.8950227023856846, 'eval_accuracy': 0.8681192660550459, 'eval_f1_score': 0.8815653964984552, 'eval_matthews_corrcoef': 0.7490285297671831}\n",
    "    \n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.6675180818107971, 'eval_accuracy': 0.9059633027522935, 'eval_f1_score': 0.9100877192982456, 'eval_matthews_corrcoef': 0.8129088273674456}    \n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.8225862858146175, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9086809470124014, 'eval_matthews_corrcoef': 0.8141675815843189}\n",
    "    \n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.7950202624074657, 'eval_accuracy': 0.9048165137614679, 'eval_f1_score': 0.9074693422519509, 'eval_matthews_corrcoef': 0.8096695019638379}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.9122233610882495, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9100998890122087, 'eval_matthews_corrcoef': 0.814418593292671}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.9783678258170956, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9110867178924259, 'eval_matthews_corrcoef': 0.8151154105091728}\n",
    "    \n",
    "    \n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.7866843587893487, 'eval_accuracy': 0.8910550458715596, 'eval_f1_score': 0.8957189901207465, 'eval_matthews_corrcoef': 0.782918425640356}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.8114843527029326, 'eval_accuracy': 0.8910550458715596, 'eval_f1_score': 0.8977395048439182, 'eval_matthews_corrcoef': 0.7851535006404734}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.7801431623559566, 'eval_accuracy': 0.9002293577981652, 'eval_f1_score': 0.903010033444816, 'eval_matthews_corrcoef': 0.8004866623608873}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.7640770616951762, 'eval_accuracy': 0.8979357798165137, 'eval_f1_score': 0.9025191675794085, 'eval_matthews_corrcoef': 0.7969024412634399}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.873492513642885, 'eval_accuracy': 0.8899082568807339, 'eval_f1_score': 0.896328293736501, 'eval_matthews_corrcoef': 0.7823782248101759}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 1.1636826317353504, 'eval_accuracy': 0.8979357798165137, 'eval_f1_score': 0.9005586592178771, 'eval_matthews_corrcoef': 0.7958453267031143}\n",
    "    \n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.8698351146473601, 'eval_accuracy': 0.9013761467889908, 'eval_f1_score': 0.9022727272727273, 'eval_matthews_corrcoef': 0.802887459817966}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.9329443228181342, 'eval_accuracy': 0.9013761467889908, 'eval_f1_score': 0.9031531531531531, 'eval_matthews_corrcoef': 0.802685863433527}\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 0.9986168684279536, 'eval_accuracy': 0.8899082568807339, 'eval_f1_score': 0.893569844789357, 'eval_matthews_corrcoef': 0.7800154387149919}\n",
    "\n",
    "\n",
    "min: tensor(, device='cuda:0', grad_fn=<MinBackward1>)\n",
    "{'eval_loss': 1.0684298671058765, 'eval_accuracy': 0.8944954128440367, 'eval_f1_score': 0.8975501113585747, 'eval_matthews_corrcoef': 0.7890387416118476}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   12\n",
      "Num steps:    56120\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab6660850314e2c90ecc30a51a1ee9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 38165248677.558525, 'train_global_step': 5613}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1938, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7866843587893487, 'eval_accuracy': 0.8910550458715596, 'eval_f1_score': 0.8957189901207465, 'eval_matthews_corrcoef': 0.782918425640356}\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8425840a44794bcbaabfe028bb7bc802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 36960637049.86567, 'train_global_step': 11226}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1734, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8114843527029326, 'eval_accuracy': 0.8910550458715596, 'eval_f1_score': 0.8977395048439182, 'eval_matthews_corrcoef': 0.7851535006404734}\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225f23135359491b8b5a07c771449cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 35690447079.32585, 'train_global_step': 16839}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1563, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7801431623559566, 'eval_accuracy': 0.9002293577981652, 'eval_f1_score': 0.903010033444816, 'eval_matthews_corrcoef': 0.8004866623608873}\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd740fd161e541f89ba51940eec059d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 34562196526.885445, 'train_global_step': 22452}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1421, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7640770616951762, 'eval_accuracy': 0.8979357798165137, 'eval_f1_score': 0.9025191675794085, 'eval_matthews_corrcoef': 0.7969024412634399}\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcf875f369940ca911d6ae8fa6a2c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 33585057180.482452, 'train_global_step': 28065}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1305, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.873492513642885, 'eval_accuracy': 0.8899082568807339, 'eval_f1_score': 0.896328293736501, 'eval_matthews_corrcoef': 0.7823782248101759}\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4763e1a08cf34ddb9ef9020b5ef703f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 32765248496.49314, 'train_global_step': 33678}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1214, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 1.1636826317353504, 'eval_accuracy': 0.8979357798165137, 'eval_f1_score': 0.9005586592178771, 'eval_matthews_corrcoef': 0.7958453267031143}\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9495b97afa4f5dae32abb8fd475278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 32106685861.969, 'train_global_step': 39291}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1145, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8698351146473601, 'eval_accuracy': 0.9013761467889908, 'eval_f1_score': 0.9022727272727273, 'eval_matthews_corrcoef': 0.802887459817966}\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c78c7691564a01a6497ad14ba23f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 31611629304.200962, 'train_global_step': 44904}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1097, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9329443228181342, 'eval_accuracy': 0.9013761467889908, 'eval_f1_score': 0.9031531531531531, 'eval_matthews_corrcoef': 0.802685863433527}\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87edc27bed614f32a91dccf504b74e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 31281257854.198467, 'train_global_step': 50517}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1069, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9986168684279536, 'eval_accuracy': 0.8899082568807339, 'eval_f1_score': 0.893569844789357, 'eval_matthews_corrcoef': 0.7800154387149919}\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83316b553a14113898f7e07cf1628ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'train_loss': 31116107923.771244, 'train_global_step': 56130}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.1059, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 1.0684298671058765, 'eval_accuracy': 0.8944954128440367, 'eval_f1_score': 0.8975501113585747, 'eval_matthews_corrcoef': 0.7890387416118476}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 31116107923.771244, 'train_global_step': 56130}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 10\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l0 = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DANCING = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   12\n",
      "Num steps:    56120\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afc06595cb14d9595834a9f8add8880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 307842.8250656957, 'train_global_step': 5613}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0962, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.5387218423426269, 'eval_accuracy': 0.9094036697247706, 'eval_f1_score': 0.9128996692392503, 'eval_matthews_corrcoef': 0.8193813835386101}\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec3da5d308425c9c41b5b970f66e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 295052.44590682344, 'train_global_step': 11226}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0813, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.6641008995419849, 'eval_accuracy': 0.9059633027522935, 'eval_f1_score': 0.90929203539823, 'eval_matthews_corrcoef': 0.8122846948750111}\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89df423fd304650bfd8d3796d9b1e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 281843.94260533585, 'train_global_step': 16839}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0690, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7388439633571672, 'eval_accuracy': 0.9071100917431193, 'eval_f1_score': 0.9061413673232909, 'eval_matthews_corrcoef': 0.8156931077584341}\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296cd413c47948fb8d70df3a50c68697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 270352.25248864247, 'train_global_step': 22452}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0589, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7115483375592367, 'eval_accuracy': 0.8990825688073395, 'eval_f1_score': 0.9020044543429844, 'eval_matthews_corrcoef': 0.7982224279797805}\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36438dff707245eab36479d6c736c9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 260577.20890677892, 'train_global_step': 28065}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0507, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8782974654087041, 'eval_accuracy': 0.9025229357798165, 'eval_f1_score': 0.9064906490649064, 'eval_matthews_corrcoef': 0.8057450987560969}\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df136b420bc4c06ac19591abf041b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 252499.97275020042, 'train_global_step': 33678}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0443, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7100696170880781, 'eval_accuracy': 0.9036697247706422, 'eval_f1_score': 0.90625, 'eval_matthews_corrcoef': 0.8073457353364165}\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5b4425d2147488cac6079a47f3c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 246091.495239845, 'train_global_step': 39291}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0395, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7614875830338866, 'eval_accuracy': 0.8979357798165137, 'eval_f1_score': 0.9029443838604144, 'eval_matthews_corrcoef': 0.7973244002694374}\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ef133db5e645e882665995b8e1f8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 241320.28395577232, 'train_global_step': 44904}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0362, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9218486394773567, 'eval_accuracy': 0.8990825688073395, 'eval_f1_score': 0.9032967032967032, 'eval_matthews_corrcoef': 0.7989302904659507}\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db0dfefbbc541bc8621a3a6910dcf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 238158.03300374132, 'train_global_step': 50517}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0342, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.8802069908331732, 'eval_accuracy': 0.9025229357798165, 'eval_f1_score': 0.9062844542447629, 'eval_matthews_corrcoef': 0.8055911309630356}\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e00b2321f24ac7987560d8ab5a4d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 236583.7542368163, 'train_global_step': 56130}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0335, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.9648801921194397, 'eval_accuracy': 0.9036697247706422, 'eval_f1_score': 0.9074889867841409, 'eval_matthews_corrcoef': 0.8079646760473406}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 236583.7542368163, 'train_global_step': 56130}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 10\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l0 = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   12\n",
      "Num steps:    56120\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba9b64201914419a1bd92fc414c2d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2334.855947157756, 'train_global_step': 5613}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0269, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.817272575814211, 'eval_accuracy': 0.8692660550458715, 'eval_f1_score': 0.8810020876826722, 'eval_matthews_corrcoef': 0.7474313474729476}\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4934b05a61f441df9fbb8ca028ac089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2215.993574051727, 'train_global_step': 11226}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0168, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.7509454794127395, 'eval_accuracy': 0.8899082568807339, 'eval_f1_score': 0.8961038961038962, 'eval_matthews_corrcoef': 0.7820885251332516}\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81de136ddde84a498095cc6f42f9a5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2095.8152182555423, 'train_global_step': 16839}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0084, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.713523751005552, 'eval_accuracy': 0.8795871559633027, 'eval_f1_score': 0.8891235480464625, 'eval_matthews_corrcoef': 0.7655753368260879}\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644bd80200aa456b90d962cee10be8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 1993.300798474245, 'train_global_step': 22452}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 0\n",
      "min: tensor(0.0017, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.6470107384116622, 'eval_accuracy': 0.8922018348623854, 'eval_f1_score': 0.8978260869565218, 'eval_matthews_corrcoef': 0.7861676019468541}\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f363163d33b45d789b2e3f583fc96e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 1907.5322962641483, 'train_global_step': 28065}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s: 1396104\n",
      "min: tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
      "{'eval_loss': 0.5541270398553879, 'eval_accuracy': 0.8853211009174312, 'eval_f1_score': 0.8938428874734606, 'eval_matthews_corrcoef': 0.776048767904275}\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667573ebf95a4203a4aea0072fdb240b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=5613, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ae701fb0ab4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                       \u001b[0mvalid_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                       checkpoint_files=checkpoint_files)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5106b92246f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, params, train_examples, valid_examples, checkpoint_files)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9b2d6fc8d342>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         _, pooled_output, penalty = self.bert(\n\u001b[0;32m---> 24\u001b[0;31m             input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ca7d654fb313>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b442b7280400>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml0_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mpenalty\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml0_penalty_bert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 1\n",
    "\n",
    "params['num_train_epochs'] = 10\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_zeroed(l0_linear_layer):\n",
    "    return (l0_linear_layer._get_mask()[0].cpu().data.numpy() == 0).sum()\n",
    "\n",
    "def num_zeroed_bert_layer(bert_layer):\n",
    "    n = num_zeroed(bert_layer.attention.self.query)\n",
    "    n += num_zeroed(bert_layer.attention.self.key)\n",
    "    n += num_zeroed(bert_layer.attention.self.value)\n",
    "    n += num_zeroed(bert_layer.attention.output.dense)\n",
    "    n += num_zeroed(bert_layer.intermediate.dense)\n",
    "    n += num_zeroed(bert_layer.output.dense)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_all(l0_linear_layer):\n",
    "    return np.prod(l0_linear_layer._get_mask()[0].cpu().data.numpy().shape)\n",
    "\n",
    "def num_all_bert_layer(bert_layer):\n",
    "    n = num_all(bert_layer.attention.self.query)\n",
    "    n += num_all(bert_layer.attention.self.key)\n",
    "    n += num_all(bert_layer.attention.self.value)\n",
    "    n += num_all(bert_layer.attention.output.dense)\n",
    "    n += num_all(bert_layer.intermediate.dense)\n",
    "    n += num_all(bert_layer.output.dense)\n",
    "    return n\n",
    "\n",
    "def zeroed_proportion(bert_layer):\n",
    "    return num_zeroed_bert_layer(bert_layer) / num_all_bert_layer(bert_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6893937852647569"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroed_proportion(model.bert.model.encoder.encoder.layer[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  tensor(0.0962, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.5387218423426269,\n",
       "   'eval_accuracy': 0.9094036697247706,\n",
       "   'eval_f1_score': 0.9128996692392503,\n",
       "   'eval_matthews_corrcoef': 0.8193813835386101}),\n",
       " (0,\n",
       "  tensor(0.0813, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.6641008995419849,\n",
       "   'eval_accuracy': 0.9059633027522935,\n",
       "   'eval_f1_score': 0.90929203539823,\n",
       "   'eval_matthews_corrcoef': 0.8122846948750111}),\n",
       " (0,\n",
       "  tensor(0.0690, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.7388439633571672,\n",
       "   'eval_accuracy': 0.9071100917431193,\n",
       "   'eval_f1_score': 0.9061413673232909,\n",
       "   'eval_matthews_corrcoef': 0.8156931077584341}),\n",
       " (0,\n",
       "  tensor(0.0589, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.7115483375592367,\n",
       "   'eval_accuracy': 0.8990825688073395,\n",
       "   'eval_f1_score': 0.9020044543429844,\n",
       "   'eval_matthews_corrcoef': 0.7982224279797805}),\n",
       " (0,\n",
       "  tensor(0.0507, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.8782974654087041,\n",
       "   'eval_accuracy': 0.9025229357798165,\n",
       "   'eval_f1_score': 0.9064906490649064,\n",
       "   'eval_matthews_corrcoef': 0.8057450987560969}),\n",
       " (0,\n",
       "  tensor(0.0443, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.7100696170880781,\n",
       "   'eval_accuracy': 0.9036697247706422,\n",
       "   'eval_f1_score': 0.90625,\n",
       "   'eval_matthews_corrcoef': 0.8073457353364165}),\n",
       " (0,\n",
       "  tensor(0.0395, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.7614875830338866,\n",
       "   'eval_accuracy': 0.8979357798165137,\n",
       "   'eval_f1_score': 0.9029443838604144,\n",
       "   'eval_matthews_corrcoef': 0.7973244002694374}),\n",
       " (0,\n",
       "  tensor(0.0362, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.9218486394773567,\n",
       "   'eval_accuracy': 0.8990825688073395,\n",
       "   'eval_f1_score': 0.9032967032967032,\n",
       "   'eval_matthews_corrcoef': 0.7989302904659507}),\n",
       " (0,\n",
       "  tensor(0.0342, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.8802069908331732,\n",
       "   'eval_accuracy': 0.9025229357798165,\n",
       "   'eval_f1_score': 0.9062844542447629,\n",
       "   'eval_matthews_corrcoef': 0.8055911309630356}),\n",
       " (0,\n",
       "  tensor(0.0335, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.9648801921194397,\n",
       "   'eval_accuracy': 0.9036697247706422,\n",
       "   'eval_f1_score': 0.9074889867841409,\n",
       "   'eval_matthews_corrcoef': 0.8079646760473406}),\n",
       " (0,\n",
       "  tensor(0.0269, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.817272575814211,\n",
       "   'eval_accuracy': 0.8692660550458715,\n",
       "   'eval_f1_score': 0.8810020876826722,\n",
       "   'eval_matthews_corrcoef': 0.7474313474729476}),\n",
       " (0,\n",
       "  tensor(0.0168, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.7509454794127395,\n",
       "   'eval_accuracy': 0.8899082568807339,\n",
       "   'eval_f1_score': 0.8961038961038962,\n",
       "   'eval_matthews_corrcoef': 0.7820885251332516}),\n",
       " (0,\n",
       "  tensor(0.0084, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.713523751005552,\n",
       "   'eval_accuracy': 0.8795871559633027,\n",
       "   'eval_f1_score': 0.8891235480464625,\n",
       "   'eval_matthews_corrcoef': 0.7655753368260879}),\n",
       " (0,\n",
       "  tensor(0.0017, device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.6470107384116622,\n",
       "   'eval_accuracy': 0.8922018348623854,\n",
       "   'eval_f1_score': 0.8978260869565218,\n",
       "   'eval_matthews_corrcoef': 0.7861676019468541}),\n",
       " (1396104,\n",
       "  tensor(0., device='cuda:0', grad_fn=<MinBackward1>),\n",
       "  {'eval_loss': 0.5541270398553879,\n",
       "   'eval_accuracy': 0.8853211009174312,\n",
       "   'eval_f1_score': 0.8938428874734606,\n",
       "   'eval_matthews_corrcoef': 0.776048767904275})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5b940720824d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDANCING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for d, ddd in DANCING:\n",
    "    print(d, ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883036"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.model.encoder.num_zeroed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22233869183811827"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1396104 / (1396104 + num_zeroed_bert_layer(model.bert.model.encoder.encoder.layer[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(3072, 768)\n",
      "(768, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7077888"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_all_bert_layer(model.bert.model.encoder.encoder.layer[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4377, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(False)\n",
    "model.bert.model.encoder.encoder.layer[0].attention.self.key._get_mask()[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): L0LinearWrapper(\n",
       "        (_origin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (key): L0LinearWrapper(\n",
       "        (_origin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (value): L0LinearWrapper(\n",
       "        (_origin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): L0LinearWrapper(\n",
       "        (_origin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): L0LinearWrapper(\n",
       "      (_origin): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): L0LinearWrapper(\n",
       "      (_origin): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    )\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.model.encoder.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "Num examples: 67349\n",
      "Batch size:   32\n",
      "Num steps:    2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2105/2105 [15:51<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.08285011941226389}\n",
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:04<00:00, 26.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2209548539067661, 'eval_accuracy': 0.9254587155963303}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.08285011941226389, 'train_global_step': 2105}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH_NUM = 2\n",
    "\n",
    "params['num_train_epochs'] = 1\n",
    "checkpoint_files = {\n",
    "    'config': 'bert_config.json',\n",
    "    'model_weigths': 'model_{}_epoch_{}.pth'.format(\n",
    "        params['task_name'], EPOCH_NUM)\n",
    "}\n",
    "\n",
    "model, result = train(model, tokenizer, params,\n",
    "                      train_examples,\n",
    "                      valid_examples=dev_examples,\n",
    "                      checkpoint_files=checkpoint_files)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "Num examples:  872\n",
      "Batch size:    8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:04<00:00, 26.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2209548539067661,\n",
       " 'eval_accuracy': 0.9254587155963303,\n",
       " 'eval_f1_score': 0.9267192784667418,\n",
       " 'eval_matthews_corrcoef': 0.8508757396537342}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, prob_preds = evaluate(model, tokenizer, params,\n",
    "                              dev_examples)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
