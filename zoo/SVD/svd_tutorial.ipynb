{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svd_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-8-lCA08Vs6m",
        "colab_type": "code",
        "outputId": "abdc61ca-2565-4e9e-fbbc-cbe0d641ea3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "sXyzFN8FyrtP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O \"SST-2.zip\" \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\"\n",
        "!unzip \"SST-2.zip\"\n",
        "# заменить username и password на свои \n",
        "!git clone https://username:password@github.com/yandexdataschool/lilbert.git\n",
        "    \n",
        "!pip install -r lilbert/requirements.txt\n",
        "!mkdir lilbert/output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n-UcdPCJys5n",
        "colab_type": "code",
        "outputId": "d49f5799-d897-477a-fc9a-b5fca5da8866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "sys.path.append('lilbert/lilbert')\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "\n",
        "from lib import data_processors, tasks\n",
        "from lib.bert import BertForSequenceClassification\n",
        "from lib.train_eval import train, evaluate, predict"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DhfT4l37yxV2",
        "colab_type": "code",
        "outputId": "07b6f65f-6637-426e-9cf4-90be6142efda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'data_dir': 'SST-2',\n",
        "    'output_dir': '../output',\n",
        "    'cache_dir': '../model_cache',\n",
        "    'task_name': 'sst2',\n",
        "    'bert_model': 'bert-base-uncased',\n",
        "    'max_seq_length': 128,\n",
        "    'train_batch_size': 32,\n",
        "    'eval_batch_size': 8,\n",
        "    'learning_rate': 2e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'num_train_epochs': 1,\n",
        "    'seed': 1331,\n",
        "    'device': torch.device(\n",
        "        'cuda' if torch.cuda.is_available()\n",
        "        else 'cpu')\n",
        "}\n",
        "\n",
        "random.seed(params['seed'])\n",
        "np.random.seed(params['seed'])\n",
        "torch.manual_seed(params['seed'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa1fba49390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "gCEl06Bgy3E_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params['num_labels'] = tasks.num_labels[params['task_name']]\n",
        "params['label_list'] = tasks.label_lists[params['task_name']]\n",
        "\n",
        "processor = tasks.processors[params['task_name']]()\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    params['bert_model'], do_lower_case=True)\n",
        "\n",
        "train_examples = processor.get_train_examples(params['data_dir'])\n",
        "dev_examples = processor.get_dev_examples(params['data_dir'])\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    params['bert_model'],\n",
        "    cache_dir=params['cache_dir'],\n",
        "    num_labels=params['num_labels']).to(params['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihstqUHgz0Zl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SVDLinear"
      ]
    },
    {
      "metadata": {
        "id": "-3URR7FXy56M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.parameter import Parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUtvHD67z5rS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SVDLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, hidden_size, bias=True):\n",
        "        super(SVDLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.u = Parameter(torch.Tensor(out_features, self.hidden_size))\n",
        "        self.s = Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.v = Parameter(torch.Tensor(self.hidden_size, in_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.init_parameters()\n",
        "\n",
        "    def init_weights(self, weight=None):\n",
        "        if weight is None:\n",
        "            init.kaiming_uniform_(self.u, a=math.sqrt(5))\n",
        "            init.uniform_(self.s, a=math.sqrt(5))\n",
        "            init.kaiming_uniform_(self.v, a=math.sqrt(5))\n",
        "        else:\n",
        "            u, s, v = np.linalg.svd(weight)\n",
        "            del self.u, self.s, self.v\n",
        "            self.u = Parameter(torch.Tensor(u[:, :self.hidden_size]))\n",
        "            self.s = Parameter(torch.Tensor(s[:self.hidden_size]))\n",
        "            self.v = Parameter(torch.Tensor(v[:self.hidden_size, :]))\n",
        "\n",
        "    def init_parameters(self, weight=None):\n",
        "        self.init_weights(weight)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(\n",
        "                torch.mm(self.u, torch.mm(torch.diag(self.s), self.v))\n",
        "            )\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.linear(input, self.v)\n",
        "        output = F.linear(output, torch.diag(self.s))\n",
        "        output = F.linear(output, self.u, self.bias)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksR6SigN1ILF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_hidden_size(in_features, out_features, compression_rate):\n",
        "    \"\"\"\n",
        "    Returns hidden size of matrices for known compression rate\n",
        "    \"\"\"\n",
        "    return int(in_features * out_features /\n",
        "               (compression_rate * (in_features + out_features + 1)))\n",
        "\n",
        "\n",
        "def find_compression_rate(in_features, out_features, hidden_size):\n",
        "    \"\"\"\n",
        "    Returns matrix compression rate for known hidden size\n",
        "    \"\"\"\n",
        "    return in_features * out_features / \\\n",
        "           (hidden_size * (in_features + out_features + 1))\n",
        "\n",
        "\n",
        "def linear_to_svd(linear_layer, hidden_size=None, compression_rate=None):\n",
        "    \"\"\"\n",
        "    Returns SVDLinear layer for linear layer with hidden size\n",
        "    equal to hidden_size parameter\n",
        "    if hidden_size is None hidden_size is calculated by the compression_rate\n",
        "    \"\"\"\n",
        "    if hidden_size is None and compression_rate is None:\n",
        "        raise ValueError(\"At least one parameter (hidden_size or compression rate) should be not None\")\n",
        "\n",
        "    dense_weight = linear_layer.weight.cpu().data.numpy()\n",
        "    in_features = linear_layer.in_features\n",
        "    out_features = linear_layer.out_features\n",
        "\n",
        "    if hidden_size is None:\n",
        "        hidden_size = find_hidden_size(\n",
        "            in_features, out_features, compression_rate\n",
        "        )\n",
        "\n",
        "    svd_linear = SVDLinear(in_features, out_features, hidden_size)\n",
        "    svd_linear.init_weights(dense_weight)\n",
        "\n",
        "    return svd_linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z90FEupi4P1g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example of changing all encoder linear layers"
      ]
    },
    {
      "metadata": {
        "id": "CTuQMVTtNDKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NC_Ela0h34k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def change_transformer_linears_to_svd(model, params, hidden_size=None, compression_rate=None):\n",
        "    \"\"\"\n",
        "    Changes all linear layers to SVDLinear layers with hidden size\n",
        "    equal to hidden_size parameter\n",
        "    if hidden_size is None hidden_size for each layer is calculated by the compression_rate\n",
        "    \"\"\"\n",
        "    if hidden_size is None and compression_rate is None:\n",
        "        raise ValueError(\"At least one parameter (hidden_size or compression rate) should be not None\")\n",
        "\n",
        "    encoder_layers = list(model.children())[0].encoder.layer\n",
        "    device = params['device']\n",
        "\n",
        "    for bert_layer in tqdm(encoder_layers):\n",
        "        attention = bert_layer.attention\n",
        "\n",
        "        attention.self.query = linear_to_svd(\n",
        "            attention.self.query,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "\n",
        "        attention.self.key = linear_to_svd(\n",
        "            attention.self.key,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "\n",
        "        attention.self.value = linear_to_svd(\n",
        "            attention.self.value,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "\n",
        "        attention.output.dense = linear_to_svd(\n",
        "            attention.output.dense,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "\n",
        "        bert_layer.intermediate.dense = linear_to_svd(\n",
        "            bert_layer.intermediate.dense,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "\n",
        "        bert_layer.output.dense = linear_to_svd(\n",
        "            bert_layer.output.dense,\n",
        "            hidden_size,\n",
        "            compression_rate\n",
        "        ).to(device)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Iky-E8X49og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from lib import size_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMj5yVs04PZX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O \"model.pt\" \"https://www.dropbox.com/s/2gclpuhipfovph2/model_baseline_from_parts.pt?dl=0\"\n",
        "model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwcAeemq47TH",
        "colab_type": "code",
        "outputId": "7b0e54cd-bb73-410a-f3a0-d8d28066c3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_size = size_utils.get_model_size(model, params['cache_dir'])\n",
        "print(\"Model initial size: {}\".format(model_size))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initial size: 417.6935796737671 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5k6gNq6P53iL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "784caedd-6550-46b3-f0af-cdbd68ca7551"
      },
      "cell_type": "code",
      "source": [
        "model = change_transformer_linears_to_svd(model, params, compression_rate=2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [01:36<00:00,  8.13s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GmXCGca56Te9",
        "colab_type": "code",
        "outputId": "94ce8e23-c3ec-426c-e1a1-f0b948a17642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "changed_model_size = size_utils.get_model_size(model, params['cache_dir'])\n",
        "print(\"Size of model with svd linear layers: {}\".format(changed_model_size))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of model with svd linear layers: 255.42891216278076 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ng1F8Pj29h-J",
        "colab_type": "code",
        "outputId": "a7ab6181-57da-4ee0-bde3-b9875a07e272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "result, prob_preds = evaluate(model, tokenizer, params,\n",
        "                              dev_examples)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:12<00:00,  8.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.805045871559633,\n",
              " 'eval_f1_score': 0.8004694835680752,\n",
              " 'eval_loss': 0.4252772675496056,\n",
              " 'eval_matthews_corrcoef': 0.6126376550212791}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "eoSVwdMP8lsn",
        "colab_type": "code",
        "outputId": "b456be0d-48c9-4163-e5db-33410f34d536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCH_NUM = 1\n",
        "\n",
        "params['num_train_epochs'] = 1\n",
        "checkpoint_files = {\n",
        "    'config': 'bert_config.json',\n",
        "    'file_to_save': 'model_{}_epoch_{}.pth'.format(\n",
        "        params['task_name'], EPOCH_NUM),\n",
        "}\n",
        "\n",
        "model, result = train(model, tokenizer, params,\n",
        "                      train_examples,\n",
        "                      valid_examples=dev2_examples,\n",
        "                      checkpoint_files=checkpoint_files)\n",
        "\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "Num examples: 67349\n",
            "Batch size:   32\n",
            "Num steps:    2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/2105 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 2105/2105 [45:43<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'train_loss': 0.1975332941656441, 'train_global_step': 2105}\n",
            "***** Running evaluation *****\n",
            "Num examples:  872\n",
            "Batch size:    8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 109/109 [00:12<00:00,  9.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2370125255110239, 'eval_accuracy': 0.9162844036697247, 'eval_f1_score': 0.9180695847362514, 'eval_matthews_corrcoef': 0.8325109894262972}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_global_step': 2105, 'train_loss': 0.1975332941656441}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}